{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1c0ff8d-7fd6-4f71-9ec8-8283454cddfc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f1c0ff8d-7fd6-4f71-9ec8-8283454cddfc",
    "outputId": "3e7271cb-14bc-4bde-d154-40931ddc023d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./venv/lib/python3.12/site-packages (2.7.1)\n",
      "Requirement already satisfied: torchvision in ./venv/lib/python3.12/site-packages (0.22.1)\n",
      "Requirement already satisfied: torchaudio in ./venv/lib/python3.12/site-packages (2.7.1)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.12/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./venv/lib/python3.12/site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.12/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./venv/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.12/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./venv/lib/python3.12/site-packages (from torch) (2025.5.1)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.12/site-packages (from torchvision) (2.2.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./venv/lib/python3.12/site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: ale_py in ./venv/lib/python3.12/site-packages (0.11.2)\n",
      "Requirement already satisfied: gymnasium in ./venv/lib/python3.12/site-packages (1.2.0)\n",
      "Requirement already satisfied: numpy>1.20 in ./venv/lib/python3.12/site-packages (from ale_py) (2.2.6)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in ./venv/lib/python3.12/site-packages (from gymnasium) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in ./venv/lib/python3.12/site-packages (from gymnasium) (4.14.1)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in ./venv/lib/python3.12/site-packages (from gymnasium) (0.0.4)\n",
      "Requirement already satisfied: opencv-python in ./venv/lib/python3.12/site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in ./venv/lib/python3.12/site-packages (from opencv-python) (2.2.6)\n",
      "Requirement already satisfied: pympler in ./venv/lib/python3.12/site-packages (1.1)\n",
      "Requirement already satisfied: logging in ./venv/lib/python3.12/site-packages (0.4.9.6)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio\n",
    "!pip3 install ale_py gymnasium\n",
    "!pip3 install opencv-python\n",
    "!pip3 install pympler\n",
    "!pip3 install logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2cd0292b-3f06-49aa-81df-26dbceb4f2de",
   "metadata": {
    "id": "2cd0292b-3f06-49aa-81df-26dbceb4f2de"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict, deque\n",
    "import random\n",
    "import sys\n",
    "from pympler import asizeof\n",
    "import gc\n",
    "import time  # Add for timing\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Patch\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import ale_py\n",
    "import gymnasium as gym\n",
    "from gymnasium.vector import SyncVectorEnv  # Correct import for gymnasium\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff8480e4-8f64-4edb-9ebc-ccf0d59d1825",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ff8480e4-8f64-4edb-9ebc-ccf0d59d1825",
    "outputId": "18fba35d-9eee-4585-82d2-1f61fa6fe3e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Created vectorized environment with 8 parallel instances\n"
     ]
    }
   ],
   "source": [
    "gym.register_envs(ale_py)\n",
    "\n",
    "# ===== CONFIGURATION =====\n",
    "# Add parallel environment settings\n",
    "N_ENVS = 8  # Number of parallel environments\n",
    "N_STEPS = 100  # Collect 100 steps before training\n",
    "N_UPDATES = 4  # Number of training updates after collecting steps\n",
    "\n",
    "# Image cropping parameters\n",
    "CROP_TOP = 34\n",
    "CROP_BOTTOM = 16\n",
    "CROP_LEFT = 0\n",
    "CROP_RIGHT = 0\n",
    "RESIZE_WIDTH = 84\n",
    "RESIZE_HEIGHT = 84\n",
    "\n",
    "# Training hyperparameters\n",
    "LEARNING_RATE = 0.1\n",
    "N_EPISODES = 100\n",
    "START_EPSILON = 0.7\n",
    "FINAL_EPSILON = 0.1\n",
    "EPSILON_DECAY = (START_EPSILON - FINAL_EPSILON) / (N_EPISODES * 1000)  # Decay per step\n",
    "DISCOUNT_FACTOR = 0.99\n",
    "MEMORY_CAPACITY = 1000000\n",
    "MEMORY_FILL_SIZE = 50000\n",
    "MINIBATCH_SIZE = 8192\n",
    "TARGET_UPDATE_FREQ = 1000\n",
    "MAX_STEPS_PER_EPISODE = 5000\n",
    "REWARD_CLIP = True\n",
    "MODEL_FILE = \"dqn_pong\"\n",
    "LOAD_MODEL = \"dqn_pong_best.pth\"  # or False\n",
    "# =========================\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create vectorized environment\n",
    "def make_env():\n",
    "    env = gym.make(\"ALE/Pong-v5\")\n",
    "    return env\n",
    "\n",
    "env_fns = [make_env for _ in range(N_ENVS)]\n",
    "vec_env = SyncVectorEnv(env_fns)\n",
    "print(f\"Created vectorized environment with {N_ENVS} parallel instances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce1583a4-ed90-4577-b3a7-9ee535065f3c",
   "metadata": {
    "id": "ce1583a4-ed90-4577-b3a7-9ee535065f3c"
   },
   "outputs": [],
   "source": [
    "# preprocessing image\n",
    "\n",
    "\n",
    "# preprocess image demonstration\n",
    "\"\"\"\n",
    "def preprocess_and_show_steps(obs):  # input: 210x160x3 RGB\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(18, 5))\n",
    "\n",
    "    # Step 1: Show original RGB image\n",
    "    axs[0].imshow(obs)\n",
    "    axs[0].set_title(\"Original RGB (210x160)\")\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    # Step 2: Convert to grayscale\n",
    "    greyscaled = np.dot(obs[..., :3], [0.299, 0.587, 0.114]).astype(np.uint8)\n",
    "    axs[1].imshow(greyscaled, cmap='gray')\n",
    "    axs[1].set_title(\"Grayscale\")\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    # Step 3: Crop image vertically (rows 95 to 195)\n",
    "    cropped = greyscaled[95:195, :]\n",
    "    axs[2].imshow(cropped, cmap='gray')\n",
    "    axs[2].set_title(\"Cropped (95:195)\")\n",
    "    axs[2].axis('off')\n",
    "\n",
    "    # Step 4: Resize to 100x50 using nearest neighbor\n",
    "    resized = cv2.resize(cropped, dsize=(50, 25), interpolation=cv2.INTER_NEAREST)\n",
    "    axs[3].imshow(resized, cmap='gray')\n",
    "    axs[3].set_title(\"Resized to 100x50\")\n",
    "    axs[3].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return resized\n",
    "\n",
    "# Run and visualize preprocessing steps\n",
    "obs, info = env.reset()\n",
    "processed = preprocess_and_show_steps(obs)\n",
    "\"\"\"\n",
    "\n",
    "def preprocess(obs,\n",
    "               crop_top=CROP_TOP,\n",
    "               crop_bottom=CROP_BOTTOM,\n",
    "               crop_left=CROP_LEFT,\n",
    "               crop_right=CROP_RIGHT,\n",
    "               resize_width=RESIZE_WIDTH,\n",
    "               resize_height=RESIZE_HEIGHT):\n",
    "    # Convert to grayscale\n",
    "    if len(obs.shape) == 3 and obs.shape[2] == 3:\n",
    "        greyscaled = np.dot(obs[..., :3], [0.299, 0.587, 0.114])\n",
    "    else:\n",
    "        greyscaled = obs\n",
    "\n",
    "    # Get image dimensions\n",
    "    height, width = greyscaled.shape\n",
    "\n",
    "    # Calculate crop boundaries\n",
    "    top_bound = crop_top\n",
    "    bottom_bound = height - crop_bottom\n",
    "    left_bound = crop_left\n",
    "    right_bound = width - crop_right\n",
    "\n",
    "    # Perform cropping\n",
    "    cropped = greyscaled[top_bound:bottom_bound, left_bound:right_bound]\n",
    "\n",
    "    # Resize\n",
    "    resized = cv2.resize(cropped, (resize_width, resize_height),\n",
    "                         interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a2e43133-51f5-48e5-b925-c3118fa97bba",
   "metadata": {
    "id": "a2e43133-51f5-48e5-b925-c3118fa97bba"
   },
   "outputs": [],
   "source": [
    "# defining neural network\n",
    "# based on this architecture: https://arxiv.org/pdf/1312.5602\n",
    "# code written by Claude Sonnet 4\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, num_actions, in_channels=4):\n",
    "        super(DQN, self).__init__()\n",
    "\n",
    "        # Convolutional layers (standard DQN architecture)\n",
    "        self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=8, stride=4)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
    "\n",
    "        # Dynamically calculate linear layer size\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, in_channels, RESIZE_HEIGHT, RESIZE_WIDTH)\n",
    "            dummy = F.relu(self.conv1(dummy))\n",
    "            dummy = F.relu(self.conv2(dummy))\n",
    "            dummy = F.relu(self.conv3(dummy))\n",
    "            self.linear_size = dummy.view(1, -1).size(1)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.linear_size, 512)\n",
    "        self.fc2 = nn.Linear(512, num_actions)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "# example input: batch of 32 preprocessed frames\n",
    "# batch_size = 32\n",
    "# input_tensor = torch.randn(batch_size, 4, 25, 50) # Corrected input shape\n",
    "\n",
    "# forward pass\n",
    "# model = DQN(env.action_space.n)\n",
    "# q_values = model(input_tensor)\n",
    "# print(f\"Input shape: {input_tensor.shape}\")\n",
    "# print(f\"Output Q-values shape: {q_values.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6eed2ab-d219-41f0-a80d-9b11b4608d48",
   "metadata": {
    "id": "a6eed2ab-d219-41f0-a80d-9b11b4608d48"
   },
   "outputs": [],
   "source": [
    "class ReplayMemory:\n",
    "    def __init__(self, capacity, state_shape):\n",
    "        self.capacity = capacity\n",
    "        self.state_shape = state_shape\n",
    "        # Pre-allocate contiguous arrays\n",
    "        self.states = np.zeros((capacity, *state_shape), dtype=np.uint8)\n",
    "        self.next_states = np.zeros((capacity, *state_shape), dtype=np.uint8)\n",
    "        self.actions = np.zeros(capacity, dtype=np.int32)\n",
    "        self.rewards = np.zeros(capacity, dtype=np.float16)  # Reduce precision\n",
    "        self.dones = np.zeros(capacity, dtype=np.bool_)\n",
    "        self.position = 0\n",
    "        self.size = 0\n",
    "\n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        self.states[self.position] = state\n",
    "        self.next_states[self.position] = next_state\n",
    "        self.actions[self.position] = action\n",
    "        self.rewards[self.position] = reward\n",
    "        self.dones[self.position] = done\n",
    "\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "        self.size = min(self.size + 1, self.capacity)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        indices = np.random.choice(self.size, batch_size, replace=False)\n",
    "        return (\n",
    "            self.states[indices],\n",
    "            self.actions[indices],\n",
    "            self.rewards[indices],\n",
    "            self.next_states[indices],\n",
    "            self.dones[indices]\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def memory_usage_gb(self):\n",
    "        total_bytes = (self.states.nbytes + self.next_states.nbytes +\n",
    "                       self.actions.nbytes + self.rewards.nbytes +\n",
    "                       self.dones.nbytes)\n",
    "        return total_bytes / (1024 ** 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98a28015-3e2b-4656-ab05-1d8fc7de1b8d",
   "metadata": {
    "id": "98a28015-3e2b-4656-ab05-1d8fc7de1b8d"
   },
   "outputs": [],
   "source": [
    "# Initialize replay memory\n",
    "state_shape = (4, RESIZE_HEIGHT, RESIZE_WIDTH)\n",
    "replay_memory = ReplayMemory(MEMORY_CAPACITY, state_shape)\n",
    "\n",
    "# Initialize networks\n",
    "online_net = DQN(gym.make(\"ALE/Pong-v5\").action_space.n).to(device)\n",
    "target_net = DQN(gym.make(\"ALE/Pong-v5\").action_space.n).to(device)\n",
    "target_net.load_state_dict(online_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "# === Load saved weights to continue training ===\n",
    "if LOAD_MODEL:\n",
    "    online_net.load_state_dict(torch.load(LOAD_MODEL, map_location=device))\n",
    "    target_net.load_state_dict(online_net.state_dict())\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.RMSprop(\n",
    "    online_net.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    alpha=0.95,\n",
    "    momentum=0.95,\n",
    "    eps=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "FS-G0nphfZUX",
   "metadata": {
    "id": "FS-G0nphfZUX"
   },
   "outputs": [],
   "source": [
    "class VectorAgent:\n",
    "    def __init__(self, num_envs, initial_epsilon, epsilon_decay, final_epsilon, discount_factor):\n",
    "        self.num_envs = num_envs\n",
    "        self.epsilon = initial_epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.final_epsilon = final_epsilon\n",
    "        self.discount_factor = discount_factor\n",
    "\n",
    "    def get_actions(self, states, model):\n",
    "        \"\"\"Get actions for all environments in a batch\"\"\"\n",
    "        # Convert states to tensor\n",
    "        states_tensor = torch.tensor(states, dtype=torch.float32, device=device) / 255.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            q_values = model(states_tensor)\n",
    "\n",
    "        # Epsilon-greedy for each environment\n",
    "        actions = q_values.argmax(1).cpu().numpy()\n",
    "        rand_mask = np.random.rand(self.num_envs) < self.epsilon\n",
    "        actions[rand_mask] = np.array([vec_env.single_action_space.sample() for _ in range(self.num_envs)])[rand_mask]\n",
    "\n",
    "        return actions\n",
    "\n",
    "    def decay_epsilon(self):\n",
    "        self.epsilon = max(self.final_epsilon, self.epsilon - self.epsilon_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "KJbwz_iTfp8H",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "KJbwz_iTfp8H",
    "outputId": "a3d30b21-a593-43b5-a12f-2de1c5dc644b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating individual environments...\n",
      "Initializing parallel environments...\n",
      "Pre-filling replay memory to 50000 transitions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pre-filling: 100%|█| 50000/50000 [01:20<00:00, 619.48it/s, Memory=5e+4, Episodes"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replay memory filled with 50000 transitions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize agent\n",
    "agent = VectorAgent(\n",
    "    num_envs=N_ENVS,\n",
    "    initial_epsilon=START_EPSILON,\n",
    "    epsilon_decay=EPSILON_DECAY,\n",
    "    final_epsilon=FINAL_EPSILON,\n",
    "    discount_factor=DISCOUNT_FACTOR,\n",
    ")\n",
    "\n",
    "# Training setup\n",
    "total_steps = 0\n",
    "episode_rewards = []\n",
    "episode_losses = []\n",
    "episode_steps = []\n",
    "best_reward = -float('inf')\n",
    "\n",
    "# Initialize frame buffers for each environment\n",
    "frame_buffers = [deque(maxlen=4) for _ in range(N_ENVS)]\n",
    "current_states = np.zeros((N_ENVS, 4, RESIZE_HEIGHT, RESIZE_WIDTH))\n",
    "\n",
    "# Create individual environments instead of vectorized env\n",
    "print(\"Creating individual environments...\")\n",
    "envs = [make_env() for _ in range(N_ENVS)]\n",
    "\n",
    "def reset_env(i):\n",
    "    \"\"\"Reset a single environment\"\"\"\n",
    "    obs, _ = envs[i].reset()\n",
    "    frame = preprocess(obs)\n",
    "    frame_buffers[i].clear()\n",
    "    for _ in range(4):\n",
    "        frame_buffers[i].append(frame)\n",
    "    return np.stack(frame_buffers[i], axis=0)\n",
    "\n",
    "# Initialize all environments\n",
    "print(\"Initializing parallel environments...\")\n",
    "for i in range(N_ENVS):\n",
    "    current_states[i] = reset_env(i)\n",
    "\n",
    "# Pre-fill replay memory \n",
    "print(f\"Pre-filling replay memory to {MEMORY_FILL_SIZE} transitions...\")\n",
    "pbar = tqdm(total=MEMORY_FILL_SIZE, desc=\"Pre-filling\")\n",
    "episodes_completed = 0\n",
    "\n",
    "# Track which environments are done\n",
    "done_flags = [False] * N_ENVS\n",
    "\n",
    "while len(replay_memory) < MEMORY_FILL_SIZE:\n",
    "    # Prepare actions\n",
    "    actions = []\n",
    "    for i in range(N_ENVS):\n",
    "        if done_flags[i]:\n",
    "            # Environment is done, we'll reset it below\n",
    "            actions.append(0)  # Dummy action, will be replaced\n",
    "        else:\n",
    "            # Get random action\n",
    "            actions.append(envs[i].action_space.sample())\n",
    "    \n",
    "    # Step all environments\n",
    "    next_obs_list = []\n",
    "    rewards_list = []\n",
    "    dones_list = []\n",
    "    truncateds_list = []\n",
    "    \n",
    "    for i in range(N_ENVS):\n",
    "        if done_flags[i]:\n",
    "            # Reset done environments\n",
    "            obs, _ = envs[i].reset()\n",
    "            frame = preprocess(obs)\n",
    "            frame_buffers[i].clear()\n",
    "            for _ in range(4):\n",
    "                frame_buffers[i].append(frame)\n",
    "            next_state = np.stack(frame_buffers[i], axis=0)\n",
    "            next_obs_list.append(obs)\n",
    "            rewards_list.append(0)\n",
    "            dones_list.append(False)\n",
    "            truncateds_list.append(False)\n",
    "            done_flags[i] = False\n",
    "        else:\n",
    "            # Step active environments\n",
    "            next_obs, reward, done, truncated, info = envs[i].step(actions[i])\n",
    "            next_obs_list.append(next_obs)\n",
    "            rewards_list.append(reward)\n",
    "            dones_list.append(done)\n",
    "            truncateds_list.append(truncated)\n",
    "    \n",
    "    # Process each environment\n",
    "    next_states = np.zeros_like(current_states)\n",
    "    for i in range(N_ENVS):\n",
    "        next_frame = preprocess(next_obs_list[i])\n",
    "        frame_buffers[i].append(next_frame)\n",
    "        next_states[i] = np.stack(frame_buffers[i], axis=0)\n",
    "        \n",
    "        if REWARD_CLIP:\n",
    "            rewards_list[i] = np.clip(rewards_list[i], -1, 1)\n",
    "        \n",
    "        # Only store transitions from active environments (not those that were just reset)\n",
    "        if not done_flags[i]:\n",
    "            replay_memory.push(\n",
    "                current_states[i].copy(),\n",
    "                actions[i],\n",
    "                rewards_list[i],\n",
    "                next_states[i].copy(),\n",
    "                dones_list[i] or truncateds_list[i]\n",
    "            )\n",
    "        \n",
    "        # Check if environment is done\n",
    "        if dones_list[i] or truncateds_list[i]:\n",
    "            done_flags[i] = True\n",
    "            episodes_completed += 1\n",
    "    \n",
    "    current_states = next_states\n",
    "    pbar.update(N_ENVS)\n",
    "    pbar.set_postfix({\"Memory\": len(replay_memory), \"Episodes\": episodes_completed})\n",
    "\n",
    "pbar.close()\n",
    "print(f\"Replay memory filled with {len(replay_memory)} transitions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d7df2a-991d-415c-b592-4a42af931bb9",
   "metadata": {
    "id": "65d7df2a-991d-415c-b592-4a42af931bb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:09:11,876 - INFO - Starting training with parallel environments...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:   0%|                                | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:09:11,881 - INFO - Starting episode 0/100\n",
      "2025-07-16 00:09:11,955 - INFO - Step 0/100 - Total Steps: 8 - Avg Reward: 0.00\n",
      "2025-07-16 00:09:23,761 - INFO - Update 0/4 - Loss: 287141.1875\n",
      "2025-07-16 00:09:56,845 - INFO - Training updates completed - Avg Loss: 706816619124841.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:   0%| | 0/100 [00:44<?, ?it/s, Avg Reward=0.00, Epsilon=0.695"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:09:56,848 - INFO - Episode 0 completed in 44.92 seconds\n",
      "2025-07-16 00:09:56,848 - INFO -   Total Steps: 800\n",
      "2025-07-16 00:09:56,849 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:09:56,849 - INFO -   Epsilon: 0.6952\n",
      "2025-07-16 00:09:56,849 - INFO -   Avg Loss: 706816619124841.2500\n",
      "2025-07-16 00:09:56,850 - INFO -   Speed: 17.8 steps/s\n",
      "2025-07-16 00:09:56,883 - INFO - New best model saved with reward: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:   1%| | 1/100 [00:45<1:14:15, 45.01s/it, Avg Reward=0.00, Eps"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with reward: 0.00\n",
      "2025-07-16 00:09:56,885 - INFO - Starting episode 1/100\n",
      "2025-07-16 00:09:56,928 - INFO - Step 0/100 - Total Steps: 808 - Avg Reward: 0.00\n",
      "2025-07-16 00:10:09,062 - INFO - Update 0/4 - Loss: 2898689534197760.0000\n",
      "2025-07-16 00:11:07,606 - INFO - Training updates completed - Avg Loss: 262190622188765184.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:   1%| | 1/100 [01:55<1:14:15, 45.01s/it, Avg Reward=0.00, Eps"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:11:07,610 - INFO - Episode 1 completed in 70.69 seconds\n",
      "2025-07-16 00:11:07,611 - INFO -   Total Steps: 1600\n",
      "2025-07-16 00:11:07,611 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:11:07,611 - INFO -   Epsilon: 0.6904\n",
      "2025-07-16 00:11:07,612 - INFO -   Avg Loss: 262190622188765184.0000\n",
      "2025-07-16 00:11:07,612 - INFO -   Speed: 13.8 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:   2%| | 2/100 [01:55<1:38:13, 60.14s/it, Avg Reward=0.00, Eps"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:11:07,613 - INFO - Starting episode 2/100\n",
      "2025-07-16 00:11:07,667 - INFO - Step 0/100 - Total Steps: 1608 - Avg Reward: 0.00\n",
      "2025-07-16 00:11:24,937 - INFO - Update 0/4 - Loss: 6097268717387776.0000\n",
      "2025-07-16 00:12:29,465 - INFO - Training updates completed - Avg Loss: 1524317415534400.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:   2%| | 2/100 [03:17<1:38:13, 60.14s/it, Avg Reward=0.00, Eps"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:12:29,468 - INFO - Episode 2 completed in 81.81 seconds\n",
      "2025-07-16 00:12:29,468 - INFO -   Total Steps: 2400\n",
      "2025-07-16 00:12:29,469 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:12:29,469 - INFO -   Epsilon: 0.6856\n",
      "2025-07-16 00:12:29,470 - INFO -   Avg Loss: 1524317415534400.0000\n",
      "2025-07-16 00:12:29,470 - INFO -   Speed: 12.1 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:   3%| | 3/100 [03:17<1:53:15, 70.05s/it, Avg Reward=0.00, Eps"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:12:29,470 - INFO - Starting episode 3/100\n",
      "2025-07-16 00:12:29,516 - INFO - Step 0/100 - Total Steps: 2408 - Avg Reward: 0.00\n",
      "2025-07-16 00:12:42,593 - INFO - Update 0/4 - Loss: 683301312.0000\n",
      "2025-07-16 00:13:27,374 - INFO - Training updates completed - Avg Loss: 316860056176.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:   3%| | 3/100 [04:15<1:53:15, 70.05s/it, Avg Reward=0.00, Eps"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:13:27,378 - INFO - Episode 3 completed in 57.87 seconds\n",
      "2025-07-16 00:13:27,378 - INFO -   Total Steps: 3200\n",
      "2025-07-16 00:13:27,378 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:13:27,379 - INFO -   Epsilon: 0.6808\n",
      "2025-07-16 00:13:27,379 - INFO -   Avg Loss: 316860056176.0000\n",
      "2025-07-16 00:13:27,380 - INFO -   Speed: 12.5 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:   4%| | 4/100 [04:15<1:44:24, 65.26s/it, Avg Reward=0.00, Eps"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:13:27,380 - INFO - Starting episode 4/100\n",
      "2025-07-16 00:13:27,425 - INFO - Step 0/100 - Total Steps: 3208 - Avg Reward: 0.00\n",
      "2025-07-16 00:13:37,636 - INFO - Update 0/4 - Loss: 34141917184.0000\n",
      "2025-07-16 00:15:02,719 - INFO - Training updates completed - Avg Loss: 18053498880.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:   4%| | 4/100 [05:50<1:44:24, 65.26s/it, Avg Reward=0.00, Eps"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:15:02,727 - INFO - Episode 4 completed in 95.31 seconds\n",
      "2025-07-16 00:15:02,729 - INFO -   Total Steps: 4000\n",
      "2025-07-16 00:15:02,730 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:15:02,730 - INFO -   Epsilon: 0.6760\n",
      "2025-07-16 00:15:02,732 - INFO -   Avg Loss: 18053498880.0000\n",
      "2025-07-16 00:15:02,733 - INFO -   Speed: 11.4 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:   5%| | 5/100 [05:50<2:00:30, 76.11s/it, Avg Reward=0.00, Eps"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:15:02,735 - INFO - Starting episode 5/100\n",
      "2025-07-16 00:15:02,920 - INFO - Step 0/100 - Total Steps: 4008 - Avg Reward: 0.00\n",
      "2025-07-16 00:15:26,556 - INFO - Update 0/4 - Loss: 4063986432.0000\n",
      "2025-07-16 00:16:56,892 - INFO - Training updates completed - Avg Loss: 3590181720.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:   5%| | 5/100 [07:45<2:00:30, 76.11s/it, Avg Reward=0.00, Eps"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:16:56,898 - INFO - Episode 5 completed in 114.01 seconds\n",
      "2025-07-16 00:16:56,899 - INFO -   Total Steps: 4800\n",
      "2025-07-16 00:16:56,900 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:16:56,901 - INFO -   Epsilon: 0.6712\n",
      "2025-07-16 00:16:56,901 - INFO -   Avg Loss: 3590181720.0000\n",
      "2025-07-16 00:16:56,902 - INFO -   Speed: 10.3 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:   6%| | 6/100 [07:45<2:19:30, 89.05s/it, Avg Reward=0.00, Eps"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:16:56,904 - INFO - Starting episode 6/100\n",
      "2025-07-16 00:16:57,077 - INFO - Step 0/100 - Total Steps: 4808 - Avg Reward: 0.00\n",
      "2025-07-16 00:17:33,930 - INFO - Update 0/4 - Loss: 13744301056.0000\n",
      "2025-07-16 00:18:55,184 - INFO - Training updates completed - Avg Loss: 13719755776.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:   6%| | 6/100 [09:43<2:19:30, 89.05s/it, Avg Reward=0.00, Eps"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:18:55,193 - INFO - Episode 6 completed in 118.15 seconds\n",
      "2025-07-16 00:18:55,195 - INFO -   Total Steps: 5600\n",
      "2025-07-16 00:18:55,196 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:18:55,196 - INFO -   Epsilon: 0.6664\n",
      "2025-07-16 00:18:55,197 - INFO -   Avg Loss: 13719755776.0000\n",
      "2025-07-16 00:18:55,199 - INFO -   Speed: 9.6 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:   7%| | 7/100 [09:43<2:32:50, 98.61s/it, Avg Reward=0.00, Eps"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:18:55,201 - INFO - Starting episode 7/100\n",
      "2025-07-16 00:18:55,405 - INFO - Step 0/100 - Total Steps: 5608 - Avg Reward: 0.00\n",
      "2025-07-16 00:19:23,199 - INFO - Update 0/4 - Loss: 2437627392.0000\n",
      "2025-07-16 00:20:59,019 - INFO - Training updates completed - Avg Loss: 5822458816.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:   7%| | 7/100 [11:47<2:32:50, 98.61s/it, Avg Reward=0.00, Eps"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:20:59,026 - INFO - Episode 7 completed in 123.66 seconds\n",
      "2025-07-16 00:20:59,027 - INFO -   Total Steps: 6400\n",
      "2025-07-16 00:20:59,029 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:20:59,030 - INFO -   Epsilon: 0.6616\n",
      "2025-07-16 00:20:59,031 - INFO -   Avg Loss: 5822458816.0000\n",
      "2025-07-16 00:20:59,032 - INFO -   Speed: 9.1 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:   8%| | 8/100 [11:47<2:43:31, 106.64s/it, Avg Reward=0.00, Ep"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:20:59,035 - INFO - Starting episode 8/100\n",
      "2025-07-16 00:20:59,235 - INFO - Step 0/100 - Total Steps: 6408 - Avg Reward: 0.00\n",
      "2025-07-16 00:21:36,529 - INFO - Update 0/4 - Loss: 15623474176.0000\n",
      "2025-07-16 00:22:39,935 - INFO - Training updates completed - Avg Loss: 7863283251.8750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:   8%| | 8/100 [13:28<2:43:31, 106.64s/it, Avg Reward=0.00, Ep"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:22:39,939 - INFO - Episode 8 completed in 100.74 seconds\n",
      "2025-07-16 00:22:39,939 - INFO -   Total Steps: 7200\n",
      "2025-07-16 00:22:39,939 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:22:39,939 - INFO -   Epsilon: 0.6568\n",
      "2025-07-16 00:22:39,940 - INFO -   Avg Loss: 7863283251.8750\n",
      "2025-07-16 00:22:39,940 - INFO -   Speed: 8.9 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:   9%| | 9/100 [13:28<2:39:01, 104.85s/it, Avg Reward=0.00, Ep"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:22:39,940 - INFO - Starting episode 9/100\n",
      "2025-07-16 00:22:39,997 - INFO - Step 0/100 - Total Steps: 7208 - Avg Reward: 0.00\n",
      "2025-07-16 00:22:56,241 - INFO - Update 0/4 - Loss: 1913644800.0000\n",
      "2025-07-16 00:24:05,352 - INFO - Training updates completed - Avg Loss: 2477647376.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:   9%| | 9/100 [14:53<2:39:01, 104.85s/it, Avg Reward=0.00, Ep"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:24:05,359 - INFO - Episode 9 completed in 85.37 seconds\n",
      "2025-07-16 00:24:05,361 - INFO -   Total Steps: 8000\n",
      "2025-07-16 00:24:05,362 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:24:05,364 - INFO -   Epsilon: 0.6520\n",
      "2025-07-16 00:24:05,364 - INFO -   Avg Loss: 2477647376.0000\n",
      "2025-07-16 00:24:05,365 - INFO -   Speed: 9.0 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  10%| | 10/100 [14:53<2:28:16, 98.85s/it, Avg Reward=0.00, Ep"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:24:05,367 - INFO - Starting episode 10/100\n",
      "2025-07-16 00:24:05,557 - INFO - Step 0/100 - Total Steps: 8008 - Avg Reward: 0.00\n",
      "2025-07-16 00:24:25,401 - INFO - Update 0/4 - Loss: 2356485632.0000\n",
      "2025-07-16 00:25:13,537 - INFO - Training updates completed - Avg Loss: 5517529728.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  10%| | 10/100 [16:01<2:28:16, 98.85s/it, Avg Reward=0.00, Ep"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:25:13,540 - INFO - Episode 10 completed in 68.02 seconds\n",
      "2025-07-16 00:25:13,541 - INFO -   Total Steps: 8800\n",
      "2025-07-16 00:25:13,541 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:25:13,541 - INFO -   Epsilon: 0.6472\n",
      "2025-07-16 00:25:13,541 - INFO -   Avg Loss: 5517529728.0000\n",
      "2025-07-16 00:25:13,542 - INFO -   Speed: 9.2 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  11%| | 11/100 [16:01<2:12:42, 89.46s/it, Avg Reward=0.00, Ep"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:25:13,542 - INFO - Starting episode 11/100\n",
      "2025-07-16 00:25:13,593 - INFO - Step 0/100 - Total Steps: 8808 - Avg Reward: 0.00\n",
      "2025-07-16 00:25:26,050 - INFO - Update 0/4 - Loss: 1114471680.0000\n",
      "2025-07-16 00:25:58,337 - INFO - Training updates completed - Avg Loss: 4451197632.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  11%| | 11/100 [16:46<2:12:42, 89.46s/it, Avg Reward=0.00, Ep"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:25:58,340 - INFO - Episode 11 completed in 44.76 seconds\n",
      "2025-07-16 00:25:58,341 - INFO -   Total Steps: 9600\n",
      "2025-07-16 00:25:58,341 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:25:58,341 - INFO -   Epsilon: 0.6424\n",
      "2025-07-16 00:25:58,341 - INFO -   Avg Loss: 4451197632.0000\n",
      "2025-07-16 00:25:58,342 - INFO -   Speed: 9.5 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  12%| | 12/100 [16:46<1:51:17, 75.88s/it, Avg Reward=0.00, Ep"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:25:58,342 - INFO - Starting episode 12/100\n",
      "2025-07-16 00:25:58,387 - INFO - Step 0/100 - Total Steps: 9608 - Avg Reward: 0.00\n",
      "2025-07-16 00:26:09,195 - INFO - Update 0/4 - Loss: 4754222080.0000\n",
      "2025-07-16 00:26:48,169 - INFO - Training updates completed - Avg Loss: 4671325184.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  12%| | 12/100 [17:36<1:51:17, 75.88s/it, Avg Reward=0.00, Ep"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:26:48,172 - INFO - Episode 12 completed in 49.79 seconds\n",
      "2025-07-16 00:26:48,173 - INFO -   Total Steps: 10400\n",
      "2025-07-16 00:26:48,173 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:26:48,173 - INFO -   Epsilon: 0.6376\n",
      "2025-07-16 00:26:48,174 - INFO -   Avg Loss: 4671325184.0000\n",
      "2025-07-16 00:26:48,174 - INFO -   Speed: 9.8 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  13%|▏| 13/100 [17:36<1:38:34, 67.99s/it, Avg Reward=0.00, Ep"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:26:48,176 - INFO - Starting episode 13/100\n",
      "2025-07-16 00:26:48,220 - INFO - Step 0/100 - Total Steps: 10408 - Avg Reward: 0.00\n",
      "2025-07-16 00:26:59,723 - INFO - Update 0/4 - Loss: 13728991232.0000\n",
      "2025-07-16 00:27:36,536 - INFO - Training updates completed - Avg Loss: 7892563392.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  13%|▏| 13/100 [18:24<1:38:34, 67.99s/it, Avg Reward=0.00, Ep"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:27:36,540 - INFO - Episode 13 completed in 48.33 seconds\n",
      "2025-07-16 00:27:36,541 - INFO -   Total Steps: 11200\n",
      "2025-07-16 00:27:36,541 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:27:36,541 - INFO -   Epsilon: 0.6328\n",
      "2025-07-16 00:27:36,541 - INFO -   Avg Loss: 7892563392.0000\n",
      "2025-07-16 00:27:36,542 - INFO -   Speed: 10.1 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  14%|▏| 14/100 [18:24<1:28:57, 62.06s/it, Avg Reward=0.00, Ep"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:27:36,542 - INFO - Starting episode 14/100\n",
      "2025-07-16 00:27:36,592 - INFO - Step 0/100 - Total Steps: 11208 - Avg Reward: 0.00\n",
      "2025-07-16 00:27:47,960 - INFO - Update 0/4 - Loss: 6425724928.0000\n",
      "2025-07-16 00:28:21,419 - INFO - Training updates completed - Avg Loss: 5678792096.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  14%|▏| 14/100 [19:09<1:28:57, 62.06s/it, Avg Reward=0.00, Ep"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:28:21,422 - INFO - Episode 14 completed in 44.84 seconds\n",
      "2025-07-16 00:28:21,423 - INFO -   Total Steps: 12000\n",
      "2025-07-16 00:28:21,423 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:28:21,424 - INFO -   Epsilon: 0.6280\n",
      "2025-07-16 00:28:21,424 - INFO -   Avg Loss: 5678792096.0000\n",
      "2025-07-16 00:28:21,424 - INFO -   Speed: 10.4 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  15%|▏| 15/100 [19:09<1:20:35, 56.88s/it, Avg Reward=0.00, Ep"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:28:21,425 - INFO - Starting episode 15/100\n",
      "2025-07-16 00:28:21,465 - INFO - Step 0/100 - Total Steps: 12008 - Avg Reward: 0.00\n",
      "2025-07-16 00:28:34,452 - INFO - Update 0/4 - Loss: 3198530560.0000\n",
      "2025-07-16 00:29:07,962 - INFO - Training updates completed - Avg Loss: 5374661504.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  15%|▏| 15/100 [19:56<1:20:35, 56.88s/it, Avg Reward=0.00, Ep"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:29:07,965 - INFO - Episode 15 completed in 46.51 seconds\n",
      "2025-07-16 00:29:07,966 - INFO -   Total Steps: 12800\n",
      "2025-07-16 00:29:07,966 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:29:07,966 - INFO -   Epsilon: 0.6232\n",
      "2025-07-16 00:29:07,966 - INFO -   Avg Loss: 5374661504.0000\n",
      "2025-07-16 00:29:07,967 - INFO -   Speed: 10.7 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  16%|▏| 16/100 [19:56<1:15:16, 53.77s/it, Avg Reward=0.00, Ep"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:29:07,967 - INFO - Starting episode 16/100\n",
      "2025-07-16 00:29:08,012 - INFO - Step 0/100 - Total Steps: 12808 - Avg Reward: 0.00\n",
      "2025-07-16 00:29:20,928 - INFO - Update 0/4 - Loss: 9771344.0000\n",
      "2025-07-16 00:29:56,929 - INFO - Training updates completed - Avg Loss: 8694062932.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  16%|▏| 16/100 [20:45<1:15:16, 53.77s/it, Avg Reward=0.00, Ep"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:29:56,933 - INFO - Episode 16 completed in 48.93 seconds\n",
      "2025-07-16 00:29:56,933 - INFO -   Total Steps: 13600\n",
      "2025-07-16 00:29:56,934 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:29:56,934 - INFO -   Epsilon: 0.6184\n",
      "2025-07-16 00:29:56,934 - INFO -   Avg Loss: 8694062932.0000\n",
      "2025-07-16 00:29:56,935 - INFO -   Speed: 10.9 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  17%|▏| 17/100 [20:45<1:12:23, 52.33s/it, Avg Reward=0.00, Ep"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:29:56,935 - INFO - Starting episode 17/100\n",
      "2025-07-16 00:29:56,978 - INFO - Step 0/100 - Total Steps: 13608 - Avg Reward: 0.00\n",
      "2025-07-16 00:30:09,977 - INFO - Update 0/4 - Loss: 11923236864.0000\n",
      "2025-07-16 00:30:45,626 - INFO - Training updates completed - Avg Loss: 4777559124.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  17%|▏| 17/100 [21:33<1:12:23, 52.33s/it, Avg Reward=0.00, Ep"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:30:45,629 - INFO - Episode 17 completed in 48.66 seconds\n",
      "2025-07-16 00:30:45,630 - INFO -   Total Steps: 14400\n",
      "2025-07-16 00:30:45,630 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:30:45,630 - INFO -   Epsilon: 0.6136\n",
      "2025-07-16 00:30:45,631 - INFO -   Avg Loss: 4777559124.0000\n",
      "2025-07-16 00:30:45,631 - INFO -   Speed: 11.1 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  18%|▏| 18/100 [21:33<1:10:01, 51.24s/it, Avg Reward=0.00, Ep"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:30:45,631 - INFO - Starting episode 18/100\n",
      "2025-07-16 00:30:45,711 - INFO - Step 0/100 - Total Steps: 14408 - Avg Reward: 0.00\n",
      "2025-07-16 00:30:57,867 - INFO - Update 0/4 - Loss: 4297549824.0000\n",
      "2025-07-16 00:31:28,069 - INFO - Training updates completed - Avg Loss: 1716429232.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  18%|▏| 18/100 [22:16<1:10:01, 51.24s/it, Avg Reward=0.00, Ep"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:31:28,072 - INFO - Episode 18 completed in 42.37 seconds\n",
      "2025-07-16 00:31:28,073 - INFO -   Total Steps: 15200\n",
      "2025-07-16 00:31:28,073 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:31:28,073 - INFO -   Epsilon: 0.6088\n",
      "2025-07-16 00:31:28,073 - INFO -   Avg Loss: 1716429232.0000\n",
      "2025-07-16 00:31:28,074 - INFO -   Speed: 11.4 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  19%|▏| 19/100 [22:16<1:05:36, 48.59s/it, Avg Reward=0.00, Ep"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:31:28,074 - INFO - Starting episode 19/100\n",
      "2025-07-16 00:31:28,117 - INFO - Step 0/100 - Total Steps: 15208 - Avg Reward: 0.00\n",
      "2025-07-16 00:31:38,620 - INFO - Update 0/4 - Loss: 97611816.0000\n",
      "2025-07-16 00:32:07,655 - INFO - Training updates completed - Avg Loss: 1012784058.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  19%|▏| 19/100 [22:55<1:05:36, 48.59s/it, Avg Reward=0.00, Ep"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:32:07,658 - INFO - Episode 19 completed in 39.55 seconds\n",
      "2025-07-16 00:32:07,658 - INFO -   Total Steps: 16000\n",
      "2025-07-16 00:32:07,658 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:32:07,659 - INFO -   Epsilon: 0.6040\n",
      "2025-07-16 00:32:07,659 - INFO -   Avg Loss: 1012784058.0000\n",
      "2025-07-16 00:32:07,660 - INFO -   Speed: 11.6 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  20%|▏| 20/100 [22:55<1:01:11, 45.89s/it, Avg Reward=0.00, Ep"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:32:07,660 - INFO - Starting episode 20/100\n",
      "2025-07-16 00:32:07,700 - INFO - Step 0/100 - Total Steps: 16008 - Avg Reward: 0.00\n",
      "2025-07-16 00:32:17,622 - INFO - Update 0/4 - Loss: 585231616.0000\n",
      "2025-07-16 00:32:46,135 - INFO - Training updates completed - Avg Loss: 818660464.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  20%|▏| 20/100 [23:34<1:01:11, 45.89s/it, Avg Reward=0.00, Ep"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:32:46,138 - INFO - Episode 20 completed in 38.45 seconds\n",
      "2025-07-16 00:32:46,139 - INFO -   Total Steps: 16800\n",
      "2025-07-16 00:32:46,139 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:32:46,139 - INFO -   Epsilon: 0.5992\n",
      "2025-07-16 00:32:46,139 - INFO -   Avg Loss: 818660464.0000\n",
      "2025-07-16 00:32:46,140 - INFO -   Speed: 11.9 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  21%|▏| 21/100 [23:34<57:29, 43.67s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:32:46,140 - INFO - Starting episode 21/100\n",
      "2025-07-16 00:32:46,183 - INFO - Step 0/100 - Total Steps: 16808 - Avg Reward: 0.00\n",
      "2025-07-16 00:32:58,530 - INFO - Update 0/4 - Loss: 976996096.0000\n",
      "2025-07-16 00:33:27,562 - INFO - Training updates completed - Avg Loss: 1341346056.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  21%|▏| 21/100 [24:15<57:29, 43.67s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:33:27,566 - INFO - Episode 21 completed in 41.39 seconds\n",
      "2025-07-16 00:33:27,566 - INFO -   Total Steps: 17600\n",
      "2025-07-16 00:33:27,566 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:33:27,567 - INFO -   Epsilon: 0.5944\n",
      "2025-07-16 00:33:27,567 - INFO -   Avg Loss: 1341346056.0000\n",
      "2025-07-16 00:33:27,568 - INFO -   Speed: 12.1 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  22%|▏| 22/100 [24:15<55:53, 42.99s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:33:27,568 - INFO - Starting episode 22/100\n",
      "2025-07-16 00:33:27,613 - INFO - Step 0/100 - Total Steps: 17608 - Avg Reward: 0.00\n",
      "2025-07-16 00:33:37,941 - INFO - Update 0/4 - Loss: 1447781632.0000\n",
      "2025-07-16 00:34:06,472 - INFO - Training updates completed - Avg Loss: 480458304.1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  22%|▏| 22/100 [24:54<55:53, 42.99s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:34:06,476 - INFO - Episode 22 completed in 38.87 seconds\n",
      "2025-07-16 00:34:06,476 - INFO -   Total Steps: 18400\n",
      "2025-07-16 00:34:06,476 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:34:06,477 - INFO -   Epsilon: 0.5896\n",
      "2025-07-16 00:34:06,477 - INFO -   Avg Loss: 480458304.1250\n",
      "2025-07-16 00:34:06,478 - INFO -   Speed: 12.3 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  23%|▏| 23/100 [24:54<53:36, 41.77s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:34:06,478 - INFO - Starting episode 23/100\n",
      "2025-07-16 00:34:06,518 - INFO - Step 0/100 - Total Steps: 18408 - Avg Reward: 0.00\n",
      "2025-07-16 00:34:16,734 - INFO - Update 0/4 - Loss: 1954122368.0000\n",
      "2025-07-16 00:34:45,333 - INFO - Training updates completed - Avg Loss: 1932066192.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  23%|▏| 23/100 [25:33<53:36, 41.77s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:34:45,337 - INFO - Episode 23 completed in 38.83 seconds\n",
      "2025-07-16 00:34:45,337 - INFO -   Total Steps: 19200\n",
      "2025-07-16 00:34:45,338 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:34:45,338 - INFO -   Epsilon: 0.5848\n",
      "2025-07-16 00:34:45,338 - INFO -   Avg Loss: 1932066192.0000\n",
      "2025-07-16 00:34:45,338 - INFO -   Speed: 12.5 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  24%|▏| 24/100 [25:33<51:48, 40.90s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:34:45,339 - INFO - Starting episode 24/100\n",
      "2025-07-16 00:34:45,379 - INFO - Step 0/100 - Total Steps: 19208 - Avg Reward: 0.00\n",
      "2025-07-16 00:34:55,403 - INFO - Update 0/4 - Loss: 2172078080.0000\n",
      "2025-07-16 00:35:22,752 - INFO - Training updates completed - Avg Loss: 1364828672.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  24%|▏| 24/100 [26:10<51:48, 40.90s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:35:22,755 - INFO - Episode 24 completed in 37.38 seconds\n",
      "2025-07-16 00:35:22,755 - INFO -   Total Steps: 20000\n",
      "2025-07-16 00:35:22,756 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:35:22,756 - INFO -   Epsilon: 0.5800\n",
      "2025-07-16 00:35:22,756 - INFO -   Avg Loss: 1364828672.0000\n",
      "2025-07-16 00:35:22,757 - INFO -   Speed: 12.7 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  25%|▎| 25/100 [26:10<49:48, 39.85s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:35:22,757 - INFO - Starting episode 25/100\n",
      "2025-07-16 00:35:22,796 - INFO - Step 0/100 - Total Steps: 20008 - Avg Reward: 0.00\n",
      "2025-07-16 00:35:34,031 - INFO - Update 0/4 - Loss: 348447488.0000\n",
      "2025-07-16 00:36:03,269 - INFO - Training updates completed - Avg Loss: 750607888.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  25%|▎| 25/100 [26:51<49:48, 39.85s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:36:03,272 - INFO - Episode 25 completed in 40.48 seconds\n",
      "2025-07-16 00:36:03,272 - INFO -   Total Steps: 20800\n",
      "2025-07-16 00:36:03,273 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:36:03,273 - INFO -   Epsilon: 0.5752\n",
      "2025-07-16 00:36:03,273 - INFO -   Avg Loss: 750607888.0000\n",
      "2025-07-16 00:36:03,273 - INFO -   Speed: 12.9 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  26%|▎| 26/100 [26:51<49:23, 40.05s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:36:03,274 - INFO - Starting episode 26/100\n",
      "2025-07-16 00:36:03,319 - INFO - Step 0/100 - Total Steps: 20808 - Avg Reward: 0.00\n",
      "2025-07-16 00:36:14,168 - INFO - Update 0/4 - Loss: 1401958528.0000\n",
      "2025-07-16 00:36:42,195 - INFO - Training updates completed - Avg Loss: 1241363136.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  26%|▎| 26/100 [27:30<49:23, 40.05s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:36:42,198 - INFO - Episode 26 completed in 38.89 seconds\n",
      "2025-07-16 00:36:42,198 - INFO -   Total Steps: 21600\n",
      "2025-07-16 00:36:42,198 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:36:42,199 - INFO -   Epsilon: 0.5704\n",
      "2025-07-16 00:36:42,199 - INFO -   Avg Loss: 1241363136.0000\n",
      "2025-07-16 00:36:42,199 - INFO -   Speed: 13.1 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  27%|▎| 27/100 [27:30<48:19, 39.71s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:36:42,200 - INFO - Starting episode 27/100\n",
      "2025-07-16 00:36:42,241 - INFO - Step 0/100 - Total Steps: 21608 - Avg Reward: 0.00\n",
      "2025-07-16 00:36:52,217 - INFO - Update 0/4 - Loss: 262411184.0000\n",
      "2025-07-16 00:37:20,020 - INFO - Training updates completed - Avg Loss: 432450892.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  27%|▎| 27/100 [28:08<48:19, 39.71s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:37:20,024 - INFO - Episode 27 completed in 37.79 seconds\n",
      "2025-07-16 00:37:20,024 - INFO -   Total Steps: 22400\n",
      "2025-07-16 00:37:20,024 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:37:20,025 - INFO -   Epsilon: 0.5656\n",
      "2025-07-16 00:37:20,025 - INFO -   Avg Loss: 432450892.0000\n",
      "2025-07-16 00:37:20,025 - INFO -   Speed: 13.3 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  28%|▎| 28/100 [28:08<46:58, 39.15s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:37:20,026 - INFO - Starting episode 28/100\n",
      "2025-07-16 00:37:20,067 - INFO - Step 0/100 - Total Steps: 22408 - Avg Reward: 0.00\n",
      "2025-07-16 00:37:29,852 - INFO - Update 0/4 - Loss: 785689664.0000\n",
      "2025-07-16 00:37:58,768 - INFO - Training updates completed - Avg Loss: 509625720.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  28%|▎| 28/100 [28:46<46:58, 39.15s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:37:58,772 - INFO - Episode 28 completed in 38.71 seconds\n",
      "2025-07-16 00:37:58,772 - INFO -   Total Steps: 23200\n",
      "2025-07-16 00:37:58,773 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:37:58,774 - INFO -   Epsilon: 0.5608\n",
      "2025-07-16 00:37:58,774 - INFO -   Avg Loss: 509625720.0000\n",
      "2025-07-16 00:37:58,774 - INFO -   Speed: 13.4 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  29%|▎| 29/100 [28:46<46:10, 39.03s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:37:58,775 - INFO - Starting episode 29/100\n",
      "2025-07-16 00:37:58,816 - INFO - Step 0/100 - Total Steps: 23208 - Avg Reward: 0.00\n",
      "2025-07-16 00:38:09,804 - INFO - Update 0/4 - Loss: 715210304.0000\n",
      "2025-07-16 00:38:38,816 - INFO - Training updates completed - Avg Loss: 966049008.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  29%|▎| 29/100 [29:26<46:10, 39.03s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:38:38,818 - INFO - Episode 29 completed in 40.01 seconds\n",
      "2025-07-16 00:38:38,819 - INFO -   Total Steps: 24000\n",
      "2025-07-16 00:38:38,819 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:38:38,819 - INFO -   Epsilon: 0.5560\n",
      "2025-07-16 00:38:38,820 - INFO -   Avg Loss: 966049008.0000\n",
      "2025-07-16 00:38:38,820 - INFO -   Speed: 13.6 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  30%|▎| 30/100 [29:26<45:53, 39.33s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:38:38,821 - INFO - Starting episode 30/100\n",
      "2025-07-16 00:38:38,860 - INFO - Step 0/100 - Total Steps: 24008 - Avg Reward: 0.00\n",
      "2025-07-16 00:38:48,675 - INFO - Update 0/4 - Loss: 625072448.0000\n",
      "2025-07-16 00:39:17,347 - INFO - Training updates completed - Avg Loss: 679233308.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  30%|▎| 30/100 [30:05<45:53, 39.33s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:39:17,351 - INFO - Episode 30 completed in 38.50 seconds\n",
      "2025-07-16 00:39:17,351 - INFO -   Total Steps: 24800\n",
      "2025-07-16 00:39:17,352 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:39:17,352 - INFO -   Epsilon: 0.5512\n",
      "2025-07-16 00:39:17,352 - INFO -   Avg Loss: 679233308.0000\n",
      "2025-07-16 00:39:17,352 - INFO -   Speed: 13.7 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  31%|▎| 31/100 [30:05<44:57, 39.09s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:39:17,353 - INFO - Starting episode 31/100\n",
      "2025-07-16 00:39:17,396 - INFO - Step 0/100 - Total Steps: 24808 - Avg Reward: 0.00\n",
      "2025-07-16 00:39:27,873 - INFO - Update 0/4 - Loss: 1775599744.0000\n",
      "2025-07-16 00:40:00,031 - INFO - Training updates completed - Avg Loss: 1685687584.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  31%|▎| 31/100 [30:48<44:57, 39.09s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:40:00,033 - INFO - Episode 31 completed in 42.65 seconds\n",
      "2025-07-16 00:40:00,034 - INFO -   Total Steps: 25600\n",
      "2025-07-16 00:40:00,034 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:40:00,034 - INFO -   Epsilon: 0.5464\n",
      "2025-07-16 00:40:00,035 - INFO -   Avg Loss: 1685687584.0000\n",
      "2025-07-16 00:40:00,035 - INFO -   Speed: 13.9 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  32%|▎| 32/100 [30:48<45:31, 40.17s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:40:00,036 - INFO - Starting episode 32/100\n",
      "2025-07-16 00:40:00,078 - INFO - Step 0/100 - Total Steps: 25608 - Avg Reward: 0.00\n",
      "2025-07-16 00:40:10,461 - INFO - Update 0/4 - Loss: 803220480.0000\n",
      "2025-07-16 00:40:40,014 - INFO - Training updates completed - Avg Loss: 495850000.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  32%|▎| 32/100 [31:28<45:31, 40.17s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:40:40,017 - INFO - Episode 32 completed in 39.95 seconds\n",
      "2025-07-16 00:40:40,018 - INFO -   Total Steps: 26400\n",
      "2025-07-16 00:40:40,019 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:40:40,019 - INFO -   Epsilon: 0.5416\n",
      "2025-07-16 00:40:40,019 - INFO -   Avg Loss: 495850000.0000\n",
      "2025-07-16 00:40:40,020 - INFO -   Speed: 14.0 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  33%|▎| 33/100 [31:28<44:47, 40.11s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:40:40,020 - INFO - Starting episode 33/100\n",
      "2025-07-16 00:40:40,060 - INFO - Step 0/100 - Total Steps: 26408 - Avg Reward: 0.00\n",
      "2025-07-16 00:40:52,856 - INFO - Update 0/4 - Loss: 788525312.0000\n",
      "2025-07-16 00:41:20,480 - INFO - Training updates completed - Avg Loss: 640280736.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  33%|▎| 33/100 [32:08<44:47, 40.11s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:41:20,484 - INFO - Episode 33 completed in 40.43 seconds\n",
      "2025-07-16 00:41:20,484 - INFO -   Total Steps: 27200\n",
      "2025-07-16 00:41:20,485 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:41:20,485 - INFO -   Epsilon: 0.5368\n",
      "2025-07-16 00:41:20,485 - INFO -   Avg Loss: 640280736.0000\n",
      "2025-07-16 00:41:20,485 - INFO -   Speed: 14.1 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  34%|▎| 34/100 [32:08<44:14, 40.22s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:41:20,486 - INFO - Starting episode 34/100\n",
      "2025-07-16 00:41:20,527 - INFO - Step 0/100 - Total Steps: 27208 - Avg Reward: 0.00\n",
      "2025-07-16 00:41:30,680 - INFO - Update 0/4 - Loss: 356389952.0000\n",
      "2025-07-16 00:41:58,578 - INFO - Training updates completed - Avg Loss: 290114476.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  34%|▎| 34/100 [32:46<44:14, 40.22s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:41:58,581 - INFO - Episode 34 completed in 38.06 seconds\n",
      "2025-07-16 00:41:58,581 - INFO -   Total Steps: 28000\n",
      "2025-07-16 00:41:58,581 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:41:58,582 - INFO -   Epsilon: 0.5320\n",
      "2025-07-16 00:41:58,582 - INFO -   Avg Loss: 290114476.0000\n",
      "2025-07-16 00:41:58,582 - INFO -   Speed: 14.2 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  35%|▎| 35/100 [32:46<42:52, 39.58s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:41:58,583 - INFO - Starting episode 35/100\n",
      "2025-07-16 00:41:58,627 - INFO - Step 0/100 - Total Steps: 28008 - Avg Reward: 0.00\n",
      "2025-07-16 00:42:09,912 - INFO - Update 0/4 - Loss: 492300448.0000\n",
      "2025-07-16 00:42:40,988 - INFO - Training updates completed - Avg Loss: 560649288.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  35%|▎| 35/100 [33:29<42:52, 39.58s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:42:40,991 - INFO - Episode 35 completed in 42.37 seconds\n",
      "2025-07-16 00:42:40,991 - INFO -   Total Steps: 28800\n",
      "2025-07-16 00:42:40,991 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:42:40,992 - INFO -   Epsilon: 0.5272\n",
      "2025-07-16 00:42:40,992 - INFO -   Avg Loss: 560649288.0000\n",
      "2025-07-16 00:42:40,992 - INFO -   Speed: 14.3 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  36%|▎| 36/100 [33:29<43:07, 40.43s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:42:40,992 - INFO - Starting episode 36/100\n",
      "2025-07-16 00:42:41,038 - INFO - Step 0/100 - Total Steps: 28808 - Avg Reward: 0.00\n",
      "2025-07-16 00:42:52,854 - INFO - Update 0/4 - Loss: 174789856.0000\n",
      "2025-07-16 00:43:24,709 - INFO - Training updates completed - Avg Loss: 468662492.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  36%|▎| 36/100 [34:12<43:07, 40.43s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:43:24,713 - INFO - Episode 36 completed in 43.69 seconds\n",
      "2025-07-16 00:43:24,713 - INFO -   Total Steps: 29600\n",
      "2025-07-16 00:43:24,714 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:43:24,714 - INFO -   Epsilon: 0.5224\n",
      "2025-07-16 00:43:24,714 - INFO -   Avg Loss: 468662492.0000\n",
      "2025-07-16 00:43:24,715 - INFO -   Speed: 14.4 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  37%|▎| 37/100 [34:12<43:29, 41.42s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:43:24,717 - INFO - Starting episode 37/100\n",
      "2025-07-16 00:43:24,761 - INFO - Step 0/100 - Total Steps: 29608 - Avg Reward: 0.00\n",
      "2025-07-16 00:43:35,541 - INFO - Update 0/4 - Loss: 415032640.0000\n",
      "2025-07-16 00:44:10,840 - INFO - Training updates completed - Avg Loss: 509302016.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  37%|▎| 37/100 [34:58<43:29, 41.42s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:44:10,844 - INFO - Episode 37 completed in 46.09 seconds\n",
      "2025-07-16 00:44:10,844 - INFO -   Total Steps: 30400\n",
      "2025-07-16 00:44:10,845 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:44:10,845 - INFO -   Epsilon: 0.5176\n",
      "2025-07-16 00:44:10,845 - INFO -   Avg Loss: 509302016.0000\n",
      "2025-07-16 00:44:10,845 - INFO -   Speed: 14.5 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  38%|▍| 38/100 [34:58<44:15, 42.83s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:44:10,846 - INFO - Starting episode 38/100\n",
      "2025-07-16 00:44:10,887 - INFO - Step 0/100 - Total Steps: 30408 - Avg Reward: 0.00\n",
      "2025-07-16 00:44:22,702 - INFO - Update 0/4 - Loss: 1078049408.0000\n",
      "2025-07-16 00:44:55,264 - INFO - Training updates completed - Avg Loss: 1134542544.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  38%|▍| 38/100 [35:43<44:15, 42.83s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:44:55,270 - INFO - Episode 38 completed in 44.39 seconds\n",
      "2025-07-16 00:44:55,270 - INFO -   Total Steps: 31200\n",
      "2025-07-16 00:44:55,271 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:44:55,271 - INFO -   Epsilon: 0.5128\n",
      "2025-07-16 00:44:55,271 - INFO -   Avg Loss: 1134542544.0000\n",
      "2025-07-16 00:44:55,272 - INFO -   Speed: 14.6 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  39%|▍| 39/100 [35:43<44:01, 43.31s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:44:55,273 - INFO - Starting episode 39/100\n",
      "2025-07-16 00:44:55,320 - INFO - Step 0/100 - Total Steps: 31208 - Avg Reward: 0.00\n",
      "2025-07-16 00:45:09,250 - INFO - Update 0/4 - Loss: 1527110656.0000\n",
      "2025-07-16 00:45:40,293 - INFO - Training updates completed - Avg Loss: 1336693808.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  39%|▍| 39/100 [36:28<44:01, 43.31s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:45:40,296 - INFO - Episode 39 completed in 44.99 seconds\n",
      "2025-07-16 00:45:40,297 - INFO -   Total Steps: 32000\n",
      "2025-07-16 00:45:40,297 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:45:40,298 - INFO -   Epsilon: 0.5080\n",
      "2025-07-16 00:45:40,298 - INFO -   Avg Loss: 1336693808.0000\n",
      "2025-07-16 00:45:40,298 - INFO -   Speed: 14.6 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  40%|▍| 40/100 [36:28<43:49, 43.83s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:45:40,299 - INFO - Starting episode 40/100\n",
      "2025-07-16 00:45:40,343 - INFO - Step 0/100 - Total Steps: 32008 - Avg Reward: 0.00\n",
      "2025-07-16 00:45:51,335 - INFO - Update 0/4 - Loss: 647788352.0000\n",
      "2025-07-16 00:46:19,254 - INFO - Training updates completed - Avg Loss: 553929352.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  40%|▍| 40/100 [37:07<43:49, 43.83s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:46:19,257 - INFO - Episode 40 completed in 38.92 seconds\n",
      "2025-07-16 00:46:19,257 - INFO -   Total Steps: 32800\n",
      "2025-07-16 00:46:19,257 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:46:19,258 - INFO -   Epsilon: 0.5032\n",
      "2025-07-16 00:46:19,258 - INFO -   Avg Loss: 553929352.0000\n",
      "2025-07-16 00:46:19,258 - INFO -   Speed: 14.7 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  41%|▍| 41/100 [37:07<41:39, 42.37s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:46:19,259 - INFO - Starting episode 41/100\n",
      "2025-07-16 00:46:19,299 - INFO - Step 0/100 - Total Steps: 32808 - Avg Reward: 0.00\n",
      "2025-07-16 00:46:29,119 - INFO - Update 0/4 - Loss: 308877728.0000\n",
      "2025-07-16 00:46:56,189 - INFO - Training updates completed - Avg Loss: 525079272.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  41%|▍| 41/100 [37:44<41:39, 42.37s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:46:56,192 - INFO - Episode 41 completed in 36.90 seconds\n",
      "2025-07-16 00:46:56,192 - INFO -   Total Steps: 33600\n",
      "2025-07-16 00:46:56,193 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:46:56,193 - INFO -   Epsilon: 0.4984\n",
      "2025-07-16 00:46:56,193 - INFO -   Avg Loss: 525079272.0000\n",
      "2025-07-16 00:46:56,193 - INFO -   Speed: 14.8 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  42%|▍| 42/100 [37:44<39:22, 40.74s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:46:56,194 - INFO - Starting episode 42/100\n",
      "2025-07-16 00:46:56,237 - INFO - Step 0/100 - Total Steps: 33608 - Avg Reward: 0.00\n",
      "2025-07-16 00:47:06,121 - INFO - Update 0/4 - Loss: 97194248.0000\n",
      "2025-07-16 00:47:34,668 - INFO - Training updates completed - Avg Loss: 424271538.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  42%|▍| 42/100 [38:22<39:22, 40.74s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:47:34,672 - INFO - Episode 42 completed in 38.44 seconds\n",
      "2025-07-16 00:47:34,672 - INFO -   Total Steps: 34400\n",
      "2025-07-16 00:47:34,672 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:47:34,673 - INFO -   Epsilon: 0.4936\n",
      "2025-07-16 00:47:34,673 - INFO -   Avg Loss: 424271538.0000\n",
      "2025-07-16 00:47:34,673 - INFO -   Speed: 14.9 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  43%|▍| 43/100 [38:22<38:03, 40.06s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:47:34,674 - INFO - Starting episode 43/100\n",
      "2025-07-16 00:47:34,716 - INFO - Step 0/100 - Total Steps: 34408 - Avg Reward: 0.00\n",
      "2025-07-16 00:47:44,986 - INFO - Update 0/4 - Loss: 654800960.0000\n",
      "2025-07-16 00:48:13,948 - INFO - Training updates completed - Avg Loss: 589836080.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  43%|▍| 43/100 [39:02<38:03, 40.06s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:48:13,951 - INFO - Episode 43 completed in 39.25 seconds\n",
      "2025-07-16 00:48:13,952 - INFO -   Total Steps: 35200\n",
      "2025-07-16 00:48:13,952 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:48:13,953 - INFO -   Epsilon: 0.4888\n",
      "2025-07-16 00:48:13,953 - INFO -   Avg Loss: 589836080.0000\n",
      "2025-07-16 00:48:13,953 - INFO -   Speed: 15.0 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  44%|▍| 44/100 [39:02<37:10, 39.83s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:48:13,954 - INFO - Starting episode 44/100\n",
      "2025-07-16 00:48:13,994 - INFO - Step 0/100 - Total Steps: 35208 - Avg Reward: 0.00\n",
      "2025-07-16 00:48:24,383 - INFO - Update 0/4 - Loss: 616673984.0000\n",
      "2025-07-16 00:48:52,920 - INFO - Training updates completed - Avg Loss: 318643920.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  44%|▍| 44/100 [39:41<37:10, 39.83s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:48:52,923 - INFO - Episode 44 completed in 38.94 seconds\n",
      "2025-07-16 00:48:52,923 - INFO -   Total Steps: 36000\n",
      "2025-07-16 00:48:52,924 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:48:52,924 - INFO -   Epsilon: 0.4840\n",
      "2025-07-16 00:48:52,925 - INFO -   Avg Loss: 318643920.0000\n",
      "2025-07-16 00:48:52,925 - INFO -   Speed: 15.1 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  45%|▍| 45/100 [39:41<36:16, 39.57s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:48:52,925 - INFO - Starting episode 45/100\n",
      "2025-07-16 00:48:52,965 - INFO - Step 0/100 - Total Steps: 36008 - Avg Reward: 0.00\n",
      "2025-07-16 00:49:03,276 - INFO - Update 0/4 - Loss: 243920704.0000\n",
      "2025-07-16 00:49:32,386 - INFO - Training updates completed - Avg Loss: 354248944.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  45%|▍| 45/100 [40:20<36:16, 39.57s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:49:32,389 - INFO - Episode 45 completed in 39.43 seconds\n",
      "2025-07-16 00:49:32,389 - INFO -   Total Steps: 36800\n",
      "2025-07-16 00:49:32,390 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:49:32,390 - INFO -   Epsilon: 0.4792\n",
      "2025-07-16 00:49:32,390 - INFO -   Avg Loss: 354248944.0000\n",
      "2025-07-16 00:49:32,391 - INFO -   Speed: 15.2 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  46%|▍| 46/100 [40:20<35:35, 39.54s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:49:32,392 - INFO - Starting episode 46/100\n",
      "2025-07-16 00:49:32,433 - INFO - Step 0/100 - Total Steps: 36808 - Avg Reward: 0.00\n",
      "2025-07-16 00:49:43,010 - INFO - Update 0/4 - Loss: 185063520.0000\n",
      "2025-07-16 00:50:14,519 - INFO - Training updates completed - Avg Loss: 399165760.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  46%|▍| 46/100 [41:02<35:35, 39.54s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:50:14,530 - INFO - Episode 46 completed in 42.11 seconds\n",
      "2025-07-16 00:50:14,530 - INFO -   Total Steps: 37600\n",
      "2025-07-16 00:50:14,531 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:50:14,531 - INFO -   Epsilon: 0.4744\n",
      "2025-07-16 00:50:14,531 - INFO -   Avg Loss: 399165760.0000\n",
      "2025-07-16 00:50:14,531 - INFO -   Speed: 15.3 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  47%|▍| 47/100 [41:02<35:36, 40.32s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:50:14,532 - INFO - Starting episode 47/100\n",
      "2025-07-16 00:50:14,591 - INFO - Step 0/100 - Total Steps: 37608 - Avg Reward: 0.00\n",
      "2025-07-16 00:50:26,036 - INFO - Update 0/4 - Loss: 319334400.0000\n",
      "2025-07-16 00:50:55,344 - INFO - Training updates completed - Avg Loss: 305014840.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  47%|▍| 47/100 [41:43<35:36, 40.32s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:50:55,349 - INFO - Episode 47 completed in 40.77 seconds\n",
      "2025-07-16 00:50:55,349 - INFO -   Total Steps: 38400\n",
      "2025-07-16 00:50:55,349 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:50:55,350 - INFO -   Epsilon: 0.4696\n",
      "2025-07-16 00:50:55,350 - INFO -   Avg Loss: 305014840.0000\n",
      "2025-07-16 00:50:55,350 - INFO -   Speed: 15.3 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  48%|▍| 48/100 [41:43<35:04, 40.47s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:50:55,351 - INFO - Starting episode 48/100\n",
      "2025-07-16 00:50:55,408 - INFO - Step 0/100 - Total Steps: 38408 - Avg Reward: 0.00\n",
      "2025-07-16 00:51:06,390 - INFO - Update 0/4 - Loss: 304284928.0000\n",
      "2025-07-16 00:51:35,619 - INFO - Training updates completed - Avg Loss: 285331872.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  48%|▍| 48/100 [42:23<35:04, 40.47s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:51:35,625 - INFO - Episode 48 completed in 40.23 seconds\n",
      "2025-07-16 00:51:35,626 - INFO -   Total Steps: 39200\n",
      "2025-07-16 00:51:35,626 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:51:35,626 - INFO -   Epsilon: 0.4648\n",
      "2025-07-16 00:51:35,627 - INFO -   Avg Loss: 285331872.0000\n",
      "2025-07-16 00:51:35,627 - INFO -   Speed: 15.4 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  49%|▍| 49/100 [42:23<34:20, 40.41s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:51:35,627 - INFO - Starting episode 49/100\n",
      "2025-07-16 00:51:35,688 - INFO - Step 0/100 - Total Steps: 39208 - Avg Reward: 0.00\n",
      "2025-07-16 00:51:45,889 - INFO - Update 0/4 - Loss: 291942240.0000\n",
      "2025-07-16 00:52:15,297 - INFO - Training updates completed - Avg Loss: 324915976.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  49%|▍| 49/100 [43:03<34:20, 40.41s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:52:15,301 - INFO - Episode 49 completed in 39.63 seconds\n",
      "2025-07-16 00:52:15,301 - INFO -   Total Steps: 40000\n",
      "2025-07-16 00:52:15,301 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:52:15,302 - INFO -   Epsilon: 0.4600\n",
      "2025-07-16 00:52:15,302 - INFO -   Avg Loss: 324915976.0000\n",
      "2025-07-16 00:52:15,303 - INFO -   Speed: 15.5 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  50%|▌| 50/100 [43:03<33:29, 40.19s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:52:15,304 - INFO - Starting episode 50/100\n",
      "2025-07-16 00:52:15,361 - INFO - Step 0/100 - Total Steps: 40008 - Avg Reward: 0.00\n",
      "2025-07-16 00:52:25,639 - INFO - Update 0/4 - Loss: 336293568.0000\n",
      "2025-07-16 00:52:54,108 - INFO - Training updates completed - Avg Loss: 292424212.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  50%|▌| 50/100 [43:42<33:29, 40.19s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:52:54,112 - INFO - Episode 50 completed in 38.77 seconds\n",
      "2025-07-16 00:52:54,113 - INFO -   Total Steps: 40800\n",
      "2025-07-16 00:52:54,113 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:52:54,113 - INFO -   Epsilon: 0.4552\n",
      "2025-07-16 00:52:54,114 - INFO -   Avg Loss: 292424212.0000\n",
      "2025-07-16 00:52:54,114 - INFO -   Speed: 15.6 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  51%|▌| 51/100 [43:42<32:29, 39.78s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:52:54,114 - INFO - Starting episode 51/100\n",
      "2025-07-16 00:52:54,156 - INFO - Step 0/100 - Total Steps: 40808 - Avg Reward: 0.00\n",
      "2025-07-16 00:53:04,634 - INFO - Update 0/4 - Loss: 407096448.0000\n",
      "2025-07-16 00:53:31,949 - INFO - Training updates completed - Avg Loss: 289419474.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  51%|▌| 51/100 [44:20<32:29, 39.78s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:53:31,952 - INFO - Episode 51 completed in 37.81 seconds\n",
      "2025-07-16 00:53:31,952 - INFO -   Total Steps: 41600\n",
      "2025-07-16 00:53:31,953 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:53:31,953 - INFO -   Epsilon: 0.4504\n",
      "2025-07-16 00:53:31,953 - INFO -   Avg Loss: 289419474.0000\n",
      "2025-07-16 00:53:31,954 - INFO -   Speed: 15.6 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  52%|▌| 52/100 [44:20<31:21, 39.20s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:53:31,965 - INFO - Starting episode 52/100\n",
      "2025-07-16 00:53:32,005 - INFO - Step 0/100 - Total Steps: 41608 - Avg Reward: 0.00\n",
      "2025-07-16 00:53:41,749 - INFO - Update 0/4 - Loss: 476065504.0000\n",
      "2025-07-16 00:54:09,048 - INFO - Training updates completed - Avg Loss: 299322798.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  52%|▌| 52/100 [44:57<31:21, 39.20s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:54:09,052 - INFO - Episode 52 completed in 37.05 seconds\n",
      "2025-07-16 00:54:09,052 - INFO -   Total Steps: 42400\n",
      "2025-07-16 00:54:09,052 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:54:09,053 - INFO -   Epsilon: 0.4456\n",
      "2025-07-16 00:54:09,053 - INFO -   Avg Loss: 299322798.0000\n",
      "2025-07-16 00:54:09,053 - INFO -   Speed: 15.7 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  53%|▌| 53/100 [44:57<30:12, 38.57s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:54:09,053 - INFO - Starting episode 53/100\n",
      "2025-07-16 00:54:09,095 - INFO - Step 0/100 - Total Steps: 42408 - Avg Reward: 0.00\n",
      "2025-07-16 00:54:19,056 - INFO - Update 0/4 - Loss: 532209152.0000\n",
      "2025-07-16 00:54:46,482 - INFO - Training updates completed - Avg Loss: 311491065.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  53%|▌| 53/100 [45:34<30:12, 38.57s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:54:46,485 - INFO - Episode 53 completed in 37.40 seconds\n",
      "2025-07-16 00:54:46,486 - INFO -   Total Steps: 43200\n",
      "2025-07-16 00:54:46,486 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:54:46,487 - INFO -   Epsilon: 0.4408\n",
      "2025-07-16 00:54:46,488 - INFO -   Avg Loss: 311491065.0000\n",
      "2025-07-16 00:54:46,488 - INFO -   Speed: 15.8 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  54%|▌| 54/100 [45:34<29:18, 38.23s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:54:46,488 - INFO - Starting episode 54/100\n",
      "2025-07-16 00:54:46,528 - INFO - Step 0/100 - Total Steps: 43208 - Avg Reward: 0.00\n",
      "2025-07-16 00:54:57,143 - INFO - Update 0/4 - Loss: 588351744.0000\n",
      "2025-07-16 00:55:24,820 - INFO - Training updates completed - Avg Loss: 327713817.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  54%|▌| 54/100 [46:12<29:18, 38.23s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:55:24,823 - INFO - Episode 54 completed in 38.30 seconds\n",
      "2025-07-16 00:55:24,823 - INFO -   Total Steps: 44000\n",
      "2025-07-16 00:55:24,824 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:55:24,824 - INFO -   Epsilon: 0.4360\n",
      "2025-07-16 00:55:24,824 - INFO -   Avg Loss: 327713817.5000\n",
      "2025-07-16 00:55:24,825 - INFO -   Speed: 15.9 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  55%|▌| 55/100 [46:12<28:41, 38.26s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:55:24,825 - INFO - Starting episode 55/100\n",
      "2025-07-16 00:55:24,870 - INFO - Step 0/100 - Total Steps: 44008 - Avg Reward: 0.00\n",
      "2025-07-16 00:55:35,870 - INFO - Update 0/4 - Loss: 630734272.0000\n",
      "2025-07-16 00:56:12,099 - INFO - Training updates completed - Avg Loss: 343357208.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  55%|▌| 55/100 [47:00<28:41, 38.26s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:56:12,104 - INFO - Episode 55 completed in 47.24 seconds\n",
      "2025-07-16 00:56:12,105 - INFO -   Total Steps: 44800\n",
      "2025-07-16 00:56:12,105 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:56:12,105 - INFO -   Epsilon: 0.4312\n",
      "2025-07-16 00:56:12,106 - INFO -   Avg Loss: 343357208.5000\n",
      "2025-07-16 00:56:12,106 - INFO -   Speed: 15.9 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  56%|▌| 56/100 [47:00<30:02, 40.97s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:56:12,107 - INFO - Starting episode 56/100\n",
      "2025-07-16 00:56:12,156 - INFO - Step 0/100 - Total Steps: 44808 - Avg Reward: 0.00\n",
      "2025-07-16 00:56:27,333 - INFO - Update 0/4 - Loss: 670806016.0000\n",
      "2025-07-16 00:57:06,503 - INFO - Training updates completed - Avg Loss: 358179820.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  56%|▌| 56/100 [47:54<30:02, 40.97s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:57:06,507 - INFO - Episode 56 completed in 54.36 seconds\n",
      "2025-07-16 00:57:06,507 - INFO -   Total Steps: 45600\n",
      "2025-07-16 00:57:06,507 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:57:06,507 - INFO -   Epsilon: 0.4264\n",
      "2025-07-16 00:57:06,508 - INFO -   Avg Loss: 358179820.2500\n",
      "2025-07-16 00:57:06,508 - INFO -   Speed: 15.9 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  57%|▌| 57/100 [47:54<32:14, 45.00s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:57:06,508 - INFO - Starting episode 57/100\n",
      "2025-07-16 00:57:06,552 - INFO - Step 0/100 - Total Steps: 45608 - Avg Reward: 0.00\n",
      "2025-07-16 00:57:20,671 - INFO - Update 0/4 - Loss: 705486912.0000\n",
      "2025-07-16 00:57:55,169 - INFO - Training updates completed - Avg Loss: 372420194.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  57%|▌| 57/100 [48:43<32:14, 45.00s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:57:55,172 - INFO - Episode 57 completed in 48.63 seconds\n",
      "2025-07-16 00:57:55,173 - INFO -   Total Steps: 46400\n",
      "2025-07-16 00:57:55,173 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:57:55,173 - INFO -   Epsilon: 0.4216\n",
      "2025-07-16 00:57:55,173 - INFO -   Avg Loss: 372420194.2500\n",
      "2025-07-16 00:57:55,173 - INFO -   Speed: 15.9 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  58%|▌| 58/100 [48:43<32:16, 46.10s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:57:55,174 - INFO - Starting episode 58/100\n",
      "2025-07-16 00:57:55,216 - INFO - Step 0/100 - Total Steps: 46408 - Avg Reward: 0.00\n",
      "2025-07-16 00:58:07,417 - INFO - Update 0/4 - Loss: 732552832.0000\n",
      "2025-07-16 00:58:41,236 - INFO - Training updates completed - Avg Loss: 383514467.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  58%|▌| 58/100 [49:29<32:16, 46.10s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:58:41,240 - INFO - Episode 58 completed in 46.03 seconds\n",
      "2025-07-16 00:58:41,240 - INFO -   Total Steps: 47200\n",
      "2025-07-16 00:58:41,241 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:58:41,241 - INFO -   Epsilon: 0.4168\n",
      "2025-07-16 00:58:41,241 - INFO -   Avg Loss: 383514467.9375\n",
      "2025-07-16 00:58:41,242 - INFO -   Speed: 15.9 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  59%|▌| 59/100 [49:29<31:29, 46.09s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:58:41,242 - INFO - Starting episode 59/100\n",
      "2025-07-16 00:58:41,289 - INFO - Step 0/100 - Total Steps: 47208 - Avg Reward: 0.00\n",
      "2025-07-16 00:58:52,575 - INFO - Update 0/4 - Loss: 756326912.0000\n",
      "2025-07-16 00:59:25,975 - INFO - Training updates completed - Avg Loss: 377888915.4062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  59%|▌| 59/100 [50:14<31:29, 46.09s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:59:25,979 - INFO - Episode 59 completed in 44.70 seconds\n",
      "2025-07-16 00:59:25,979 - INFO -   Total Steps: 48000\n",
      "2025-07-16 00:59:25,980 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 00:59:25,980 - INFO -   Epsilon: 0.4120\n",
      "2025-07-16 00:59:25,980 - INFO -   Avg Loss: 377888915.4062\n",
      "2025-07-16 00:59:25,980 - INFO -   Speed: 15.9 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  60%|▌| 60/100 [50:14<30:27, 45.68s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 00:59:25,981 - INFO - Starting episode 60/100\n",
      "2025-07-16 00:59:26,023 - INFO - Step 0/100 - Total Steps: 48008 - Avg Reward: 0.00\n",
      "2025-07-16 00:59:38,396 - INFO - Update 0/4 - Loss: 669853376.0000\n",
      "2025-07-16 01:00:12,844 - INFO - Training updates completed - Avg Loss: 361424176.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  60%|▌| 60/100 [51:00<30:27, 45.68s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 01:00:12,860 - INFO - Episode 60 completed in 46.83 seconds\n",
      "2025-07-16 01:00:12,860 - INFO -   Total Steps: 48800\n",
      "2025-07-16 01:00:12,860 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 01:00:12,861 - INFO -   Epsilon: 0.4072\n",
      "2025-07-16 01:00:12,861 - INFO -   Avg Loss: 361424176.0000\n",
      "2025-07-16 01:00:12,861 - INFO -   Speed: 15.9 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  61%|▌| 61/100 [51:00<29:55, 46.04s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 01:00:12,862 - INFO - Starting episode 61/100\n",
      "2025-07-16 01:00:12,910 - INFO - Step 0/100 - Total Steps: 48808 - Avg Reward: 0.00\n",
      "2025-07-16 01:00:24,481 - INFO - Update 0/4 - Loss: 551332608.0000\n",
      "2025-07-16 01:00:59,223 - INFO - Training updates completed - Avg Loss: 383868980.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  61%|▌| 61/100 [51:47<29:55, 46.04s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 01:00:59,233 - INFO - Episode 61 completed in 46.33 seconds\n",
      "2025-07-16 01:00:59,233 - INFO -   Total Steps: 49600\n",
      "2025-07-16 01:00:59,233 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 01:00:59,234 - INFO -   Epsilon: 0.4024\n",
      "2025-07-16 01:00:59,234 - INFO -   Avg Loss: 383868980.0000\n",
      "2025-07-16 01:00:59,234 - INFO -   Speed: 16.0 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  62%|▌| 62/100 [51:47<29:13, 46.14s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 01:00:59,234 - INFO - Starting episode 62/100\n",
      "2025-07-16 01:00:59,292 - INFO - Step 0/100 - Total Steps: 49608 - Avg Reward: 0.00\n",
      "2025-07-16 01:01:09,937 - INFO - Update 0/4 - Loss: 525027968.0000\n",
      "2025-07-16 01:01:42,297 - INFO - Training updates completed - Avg Loss: 384468808.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  62%|▌| 62/100 [52:30<29:13, 46.14s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 01:01:42,301 - INFO - Episode 62 completed in 43.02 seconds\n",
      "2025-07-16 01:01:42,301 - INFO -   Total Steps: 50400\n",
      "2025-07-16 01:01:42,301 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 01:01:42,302 - INFO -   Epsilon: 0.3976\n",
      "2025-07-16 01:01:42,302 - INFO -   Avg Loss: 384468808.0000\n",
      "2025-07-16 01:01:42,302 - INFO -   Speed: 16.0 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  63%|▋| 63/100 [52:30<27:53, 45.22s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 01:01:42,303 - INFO - Starting episode 63/100\n",
      "2025-07-16 01:01:42,343 - INFO - Step 0/100 - Total Steps: 50408 - Avg Reward: 0.00\n",
      "2025-07-16 01:01:54,788 - INFO - Update 0/4 - Loss: 551399232.0000\n",
      "2025-07-16 01:02:27,235 - INFO - Training updates completed - Avg Loss: 350560508.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  63%|▋| 63/100 [53:15<27:53, 45.22s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 01:02:27,239 - INFO - Episode 63 completed in 44.90 seconds\n",
      "2025-07-16 01:02:27,239 - INFO -   Total Steps: 51200\n",
      "2025-07-16 01:02:27,240 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 01:02:27,240 - INFO -   Epsilon: 0.3928\n",
      "2025-07-16 01:02:27,240 - INFO -   Avg Loss: 350560508.0000\n",
      "2025-07-16 01:02:27,241 - INFO -   Speed: 16.0 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  64%|▋| 64/100 [53:15<27:04, 45.14s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 01:02:27,241 - INFO - Starting episode 64/100\n",
      "2025-07-16 01:02:27,282 - INFO - Step 0/100 - Total Steps: 51208 - Avg Reward: 0.00\n",
      "2025-07-16 01:02:38,023 - INFO - Update 0/4 - Loss: 509509376.0000\n",
      "2025-07-16 01:03:09,637 - INFO - Training updates completed - Avg Loss: 317527048.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  64%|▋| 64/100 [53:57<27:04, 45.14s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 01:03:09,641 - INFO - Episode 64 completed in 42.37 seconds\n",
      "2025-07-16 01:03:09,642 - INFO -   Total Steps: 52000\n",
      "2025-07-16 01:03:09,643 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 01:03:09,644 - INFO -   Epsilon: 0.3880\n",
      "2025-07-16 01:03:09,644 - INFO -   Avg Loss: 317527048.0000\n",
      "2025-07-16 01:03:09,644 - INFO -   Speed: 16.1 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  65%|▋| 65/100 [53:57<25:51, 44.32s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 01:03:09,645 - INFO - Starting episode 65/100\n",
      "2025-07-16 01:03:09,686 - INFO - Step 0/100 - Total Steps: 52008 - Avg Reward: 0.00\n",
      "2025-07-16 01:03:23,608 - INFO - Update 0/4 - Loss: 378545504.0000\n",
      "2025-07-16 01:03:52,962 - INFO - Training updates completed - Avg Loss: 323417272.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  65%|▋| 65/100 [54:41<25:51, 44.32s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 01:03:52,965 - INFO - Episode 65 completed in 43.29 seconds\n",
      "2025-07-16 01:03:52,966 - INFO -   Total Steps: 52800\n",
      "2025-07-16 01:03:52,966 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 01:03:52,966 - INFO -   Epsilon: 0.3832\n",
      "2025-07-16 01:03:52,966 - INFO -   Avg Loss: 323417272.0000\n",
      "2025-07-16 01:03:52,967 - INFO -   Speed: 16.1 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  66%|▋| 66/100 [54:41<24:56, 44.02s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 01:03:52,967 - INFO - Starting episode 66/100\n",
      "2025-07-16 01:03:53,008 - INFO - Step 0/100 - Total Steps: 52808 - Avg Reward: 0.00\n",
      "2025-07-16 01:04:03,585 - INFO - Update 0/4 - Loss: 354654464.0000\n",
      "2025-07-16 01:04:35,178 - INFO - Training updates completed - Avg Loss: 377607880.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  66%|▋| 66/100 [55:23<24:56, 44.02s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 01:04:35,180 - INFO - Episode 66 completed in 42.18 seconds\n",
      "2025-07-16 01:04:35,181 - INFO -   Total Steps: 53600\n",
      "2025-07-16 01:04:35,181 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 01:04:35,181 - INFO -   Epsilon: 0.3784\n",
      "2025-07-16 01:04:35,182 - INFO -   Avg Loss: 377607880.0000\n",
      "2025-07-16 01:04:35,182 - INFO -   Speed: 16.1 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  67%|▋| 67/100 [55:23<23:54, 43.48s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 01:04:35,182 - INFO - Starting episode 67/100\n",
      "2025-07-16 01:04:35,223 - INFO - Step 0/100 - Total Steps: 53608 - Avg Reward: 0.00\n",
      "2025-07-16 01:04:45,668 - INFO - Update 0/4 - Loss: 265423424.0000\n",
      "2025-07-16 01:05:20,266 - INFO - Training updates completed - Avg Loss: 306808768.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  67%|▋| 67/100 [56:08<23:54, 43.48s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 01:05:20,270 - INFO - Episode 67 completed in 45.06 seconds\n",
      "2025-07-16 01:05:20,271 - INFO -   Total Steps: 54400\n",
      "2025-07-16 01:05:20,272 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 01:05:20,272 - INFO -   Epsilon: 0.3736\n",
      "2025-07-16 01:05:20,273 - INFO -   Avg Loss: 306808768.0000\n",
      "2025-07-16 01:05:20,273 - INFO -   Speed: 16.2 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  68%|▋| 68/100 [56:08<23:26, 43.96s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 01:05:20,274 - INFO - Starting episode 68/100\n",
      "2025-07-16 01:05:20,315 - INFO - Step 0/100 - Total Steps: 54408 - Avg Reward: 0.00\n",
      "2025-07-16 01:05:30,858 - INFO - Update 0/4 - Loss: 260614432.0000\n",
      "2025-07-16 01:06:02,469 - INFO - Training updates completed - Avg Loss: 358636264.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  68%|▋| 68/100 [56:50<23:26, 43.96s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 01:06:02,473 - INFO - Episode 68 completed in 42.17 seconds\n",
      "2025-07-16 01:06:02,474 - INFO -   Total Steps: 55200\n",
      "2025-07-16 01:06:02,474 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 01:06:02,474 - INFO -   Epsilon: 0.3688\n",
      "2025-07-16 01:06:02,475 - INFO -   Avg Loss: 358636264.0000\n",
      "2025-07-16 01:06:02,475 - INFO -   Speed: 16.2 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  69%|▋| 69/100 [56:50<22:26, 43.43s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 01:06:02,475 - INFO - Starting episode 69/100\n",
      "2025-07-16 01:06:02,517 - INFO - Step 0/100 - Total Steps: 55208 - Avg Reward: 0.00\n",
      "2025-07-16 01:06:13,374 - INFO - Update 0/4 - Loss: 434240320.0000\n",
      "2025-07-16 01:06:44,474 - INFO - Training updates completed - Avg Loss: 320918224.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  69%|▋| 69/100 [57:32<22:26, 43.43s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 01:06:44,477 - INFO - Episode 69 completed in 41.97 seconds\n",
      "2025-07-16 01:06:44,477 - INFO -   Total Steps: 56000\n",
      "2025-07-16 01:06:44,478 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 01:06:44,478 - INFO -   Epsilon: 0.3640\n",
      "2025-07-16 01:06:44,478 - INFO -   Avg Loss: 320918224.0000\n",
      "2025-07-16 01:06:44,478 - INFO -   Speed: 16.2 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  70%|▋| 70/100 [57:32<21:30, 43.00s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 01:06:44,479 - INFO - Starting episode 70/100\n",
      "2025-07-16 01:06:44,521 - INFO - Step 0/100 - Total Steps: 56008 - Avg Reward: 0.00\n",
      "2025-07-16 01:06:54,965 - INFO - Update 0/4 - Loss: 363145152.0000\n",
      "2025-07-16 01:07:39,203 - INFO - Training updates completed - Avg Loss: 296277116.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  70%|▋| 70/100 [58:27<21:30, 43.00s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 01:07:39,215 - INFO - Episode 70 completed in 54.70 seconds\n",
      "2025-07-16 01:07:39,215 - INFO -   Total Steps: 56800\n",
      "2025-07-16 01:07:39,215 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 01:07:39,216 - INFO -   Epsilon: 0.3592\n",
      "2025-07-16 01:07:39,216 - INFO -   Avg Loss: 296277116.0000\n",
      "2025-07-16 01:07:39,216 - INFO -   Speed: 16.2 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  71%|▋| 71/100 [58:27<22:29, 46.52s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 01:07:39,217 - INFO - Starting episode 71/100\n",
      "2025-07-16 01:07:39,281 - INFO - Step 0/100 - Total Steps: 56808 - Avg Reward: 0.00\n",
      "2025-07-16 01:07:53,467 - INFO - Update 0/4 - Loss: 436509952.0000\n",
      "2025-07-16 01:08:34,013 - INFO - Training updates completed - Avg Loss: 340612444.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  71%|▋| 71/100 [59:22<22:29, 46.52s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 01:08:34,018 - INFO - Episode 71 completed in 54.76 seconds\n",
      "2025-07-16 01:08:34,018 - INFO -   Total Steps: 57600\n",
      "2025-07-16 01:08:34,019 - INFO -   Avg Reward (50): 0.00\n",
      "2025-07-16 01:08:34,019 - INFO -   Epsilon: 0.3544\n",
      "2025-07-16 01:08:34,019 - INFO -   Avg Loss: 340612444.0000\n",
      "2025-07-16 01:08:34,020 - INFO -   Speed: 16.2 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:  72%|▋| 72/100 [59:22<22:52, 49.01s/it, Avg Reward=0.00, Epsi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-16 01:08:34,020 - INFO - Starting episode 72/100\n",
      "2025-07-16 01:08:34,064 - INFO - Step 0/100 - Total Steps: 57608 - Avg Reward: 0.00\n",
      "2025-07-16 01:08:46,648 - INFO - Update 0/4 - Loss: 374189376.0000\n"
     ]
    }
   ],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"training.log\"),\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Training loop with parallel environments - LOGGING VERSION\n",
    "logger.info(\"Starting training with parallel environments...\")\n",
    "total_updates = 0\n",
    "start_time = time.time()\n",
    "episode_rewards = []      # Track all completed episode rewards\n",
    "episode_steps_list = []   # Track all completed episode steps\n",
    "episode_losses = []       # Track losses per training update\n",
    "best_reward = -float('inf')\n",
    "\n",
    "# Keep the episode progress bar but remove nested bars\n",
    "episode_pbar = tqdm(range(N_EPISODES), desc=\"Training Episodes\")\n",
    "\n",
    "for episode in episode_pbar:\n",
    "    # Log episode start\n",
    "    logger.info(f\"Starting episode {episode}/{N_EPISODES}\")\n",
    "    \n",
    "    # Reset all environments at the start of each episode\n",
    "    obs, _ = vec_env.reset()\n",
    "    # Reinitialize frame buffers and current states\n",
    "    frame_buffers = [deque(maxlen=4) for _ in range(N_ENVS)]\n",
    "    current_states = np.zeros((N_ENVS, 4, RESIZE_HEIGHT, RESIZE_WIDTH))\n",
    "    for i in range(N_ENVS):\n",
    "        frame = preprocess(obs[i])\n",
    "        for _ in range(4):\n",
    "            frame_buffers[i].append(frame)\n",
    "        current_states[i] = np.stack(frame_buffers[i], axis=0)\n",
    "\n",
    "    # Per-environment tracking\n",
    "    episode_rewards_current = np.zeros(N_ENVS)   # Rewards for current episode in each env\n",
    "    episode_steps_current = np.zeros(N_ENVS)     # Steps for current episode in each env\n",
    "\n",
    "    # Collect N_STEPS from all environments - no nested progress bar\n",
    "    episode_start_time = time.time()\n",
    "    step_losses = []\n",
    "    \n",
    "    for step in range(N_STEPS):\n",
    "        # Get actions for all environments\n",
    "        actions = agent.get_actions(current_states, online_net)\n",
    "\n",
    "        # Step all environments\n",
    "        next_obs, rewards, dones, truncateds, infos = vec_env.step(actions)\n",
    "\n",
    "        # Process each environment\n",
    "        next_states = np.zeros_like(current_states)\n",
    "        for i in range(N_ENVS):\n",
    "            # Preprocess frame\n",
    "            next_frame = preprocess(next_obs[i])\n",
    "\n",
    "            # Update frame buffer\n",
    "            frame_buffers[i].append(next_frame)\n",
    "            next_states[i] = np.stack(frame_buffers[i], axis=0)\n",
    "\n",
    "            # Clip reward\n",
    "            if REWARD_CLIP:\n",
    "                rewards[i] = np.clip(rewards[i], -10, 10)\n",
    "\n",
    "            # Update tracking\n",
    "            episode_rewards_current[i] += rewards[i]\n",
    "            episode_steps_current[i] += 1\n",
    "\n",
    "            # Store transition\n",
    "            replay_memory.push(\n",
    "                current_states[i].copy(),\n",
    "                actions[i],\n",
    "                rewards[i],\n",
    "                next_states[i].copy(),\n",
    "                dones[i] or truncateds[i]\n",
    "            )\n",
    "\n",
    "            # Reset if done\n",
    "            if dones[i] or truncateds[i]:\n",
    "                # Record completed episode\n",
    "                episode_rewards.append(episode_rewards_current[i])\n",
    "                episode_steps_list.append(episode_steps_current[i])\n",
    "\n",
    "                # Log completed episode\n",
    "                logger.info(f\"Env {i} completed episode with reward: {episode_rewards_current[i]:.2f}\")\n",
    "\n",
    "                # Reset tracking\n",
    "                episode_rewards_current[i] = 0\n",
    "                episode_steps_current[i] = 0\n",
    "\n",
    "                # Reset environment\n",
    "                vec_env.reset_async(indices=[i])\n",
    "                reset_obs, _ = vec_env.reset_wait(indices=[i])\n",
    "                frame = preprocess(reset_obs[0])\n",
    "                frame_buffers[i].clear()\n",
    "                for _ in range(4):\n",
    "                    frame_buffers[i].append(frame)\n",
    "                next_states[i] = np.stack(frame_buffers[i], axis=0)\n",
    "\n",
    "        current_states = next_states\n",
    "        total_steps += N_ENVS\n",
    "\n",
    "        # Log every 100 steps\n",
    "        if step % 100 == 0:\n",
    "            avg_reward = np.mean(episode_rewards[-10:]) if episode_rewards else 0\n",
    "            logger.info(f\"Step {step}/{N_STEPS} - Total Steps: {total_steps} - Avg Reward: {avg_reward:.2f}\")\n",
    "\n",
    "    # Training updates - no nested progress bar\n",
    "    if len(replay_memory) > MINIBATCH_SIZE:\n",
    "        step_losses = []\n",
    "        for update in range(N_UPDATES):\n",
    "            batch_data = replay_memory.sample(MINIBATCH_SIZE)\n",
    "            states, actions, rewards, next_states, dones = batch_data\n",
    "\n",
    "            # Convert to tensors\n",
    "            states_tensor = torch.as_tensor(states, device=device, dtype=torch.float32) / 255.0\n",
    "            next_states_tensor = torch.as_tensor(next_states, device=device, dtype=torch.float32) / 255.0\n",
    "            actions_tensor = torch.as_tensor(actions, device=device, dtype=torch.long)\n",
    "            rewards_tensor = torch.as_tensor(rewards, device=device, dtype=torch.float32)\n",
    "            dones_tensor = torch.as_tensor(dones, device=device, dtype=torch.float32)\n",
    "\n",
    "            # Compute Q-values\n",
    "            current_q = online_net(states_tensor).gather(1, actions_tensor.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "            # Compute target Q-values\n",
    "            with torch.no_grad():\n",
    "                next_q = target_net(next_states_tensor).max(1)[0]\n",
    "                target_q = rewards_tensor + DISCOUNT_FACTOR * next_q * (1 - dones_tensor)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = F.mse_loss(current_q, target_q)\n",
    "            step_losses.append(loss.item())\n",
    "\n",
    "            # Optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # Gradient clipping\n",
    "            for param in online_net.parameters():\n",
    "                if param.grad is not None:\n",
    "                    param.grad.data.clamp_(-1, 1)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            total_updates += 1\n",
    "\n",
    "            # Log every 5 updates\n",
    "            if update % 5 == 0:\n",
    "                logger.info(f\"Update {update}/{N_UPDATES} - Loss: {loss.item():.4f}\")\n",
    "\n",
    "        avg_loss = sum(step_losses) / len(step_losses) if step_losses else 0\n",
    "        episode_losses.append(avg_loss)\n",
    "        logger.info(f\"Training updates completed - Avg Loss: {avg_loss:.4f}\")\n",
    "    else:\n",
    "        episode_losses.append(0)\n",
    "        logger.info(\"Skipping training updates (insufficient samples)\")\n",
    "\n",
    "    # Update target network\n",
    "    if total_updates % (TARGET_UPDATE_FREQ // N_UPDATES) == 0:\n",
    "        target_net.load_state_dict(online_net.state_dict())\n",
    "        logger.info(\"Target network updated\")\n",
    "\n",
    "    # Decay epsilon\n",
    "    for _ in range(N_STEPS * N_ENVS):\n",
    "        agent.decay_epsilon()\n",
    "\n",
    "    # Calculate metrics\n",
    "    avg_reward = np.mean(episode_rewards[-50:]) if episode_rewards else 0\n",
    "    avg_steps = np.mean(episode_steps_list[-50:]) if episode_steps_list else 0\n",
    "    elapsed = time.time() - start_time\n",
    "    steps_per_sec = total_steps / elapsed if elapsed > 0 else 0\n",
    "    episode_time = time.time() - episode_start_time\n",
    "\n",
    "    # Update episode progress bar\n",
    "    episode_pbar.set_postfix({\n",
    "        \"Avg Reward\": f\"{avg_reward:.2f}\",\n",
    "        \"Epsilon\": f\"{agent.epsilon:.4f}\",\n",
    "        \"Avg Loss\": f\"{episode_losses[-1]:.4f}\",\n",
    "        \"Speed\": f\"{steps_per_sec:.1f} steps/s\"\n",
    "    })\n",
    "\n",
    "    # Log episode completion\n",
    "    logger.info(f\"Episode {episode} completed in {episode_time:.2f} seconds\")\n",
    "    logger.info(f\"  Total Steps: {total_steps}\")\n",
    "    logger.info(f\"  Avg Reward (50): {avg_reward:.2f}\")\n",
    "    logger.info(f\"  Epsilon: {agent.epsilon:.4f}\")\n",
    "    logger.info(f\"  Avg Loss: {episode_losses[-1]:.4f}\")\n",
    "    logger.info(f\"  Speed: {steps_per_sec:.1f} steps/s\")\n",
    "\n",
    "    # Save best model\n",
    "    if avg_reward > best_reward:\n",
    "        best_reward = avg_reward\n",
    "        torch.save(online_net.state_dict(), f\"{MODEL_FILE}_best.pth\")\n",
    "        logger.info(f\"New best model saved with reward: {avg_reward:.2f}\")\n",
    "        episode_pbar.write(f\"New best model saved with reward: {avg_reward:.2f}\")\n",
    "\n",
    "# Final save and cleanup\n",
    "torch.save(online_net.state_dict(), f\"{MODEL_FILE}_final.pth\")\n",
    "episode_pbar.close()\n",
    "logger.info(\"Training complete. Models saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0997e2-f9ee-4517-9786-8d63ac852139",
   "metadata": {
    "id": "ed0997e2-f9ee-4517-9786-8d63ac852139"
   },
   "outputs": [],
   "source": [
    "# Plot results\n",
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "# Plot rewards\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(episode_rewards)\n",
    "plt.title(\"Episode Rewards\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Total Reward\")\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(episode_losses)\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Average Loss\")\n",
    "\n",
    "# Plot steps\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(episode_steps)\n",
    "plt.title(\"Episode Steps\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Steps Taken\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"training_results.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gKX-Po44dKsa",
   "metadata": {
    "id": "gKX-Po44dKsa"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
