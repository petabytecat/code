_wandb:
    value:
        cli_version: 0.21.0
        code_path: code/0SRSI/pong_play_rainbow.py
        e:
            vp5xfr22lyxaal6ovydfvxo5imulaj4t:
                apple:
                    ecpuCores: 4
                    gpuCores: 10
                    memoryGb: 8
                    name: Apple M2
                    pcpuCores: 4
                    ramTotalBytes: "8589934592"
                    swapTotalBytes: "7516192768"
                codePath: 0SRSI/pong_play_rainbow.py
                codePathLocal: pong_play_rainbow.py
                cpu_count: 8
                cpu_count_logical: 8
                disk:
                    /:
                        total: "245107195904"
                        used: "236362784768"
                email: david.zhangblade@gmail.com
                executable: /Users/dewei.zhang/Documents/GitHub/code/0SRSI/venv/bin/python3
                git:
                    commit: e22805c86a1d0ffc40971f319e4cbe2b003ea4a6
                    remote: https://github.com/petabytecat/code.git
                host: KL-25861
                memory:
                    total: "8589934592"
                os: macOS-15.5-arm64-arm-64bit
                program: /Users/dewei.zhang/Documents/GitHub/code/0SRSI/pong_play_rainbow.py
                python: CPython 3.12.0
                root: /Users/dewei.zhang/Documents/GitHub/code/0SRSI
                startedAt: "2025-08-06T14:37:29.259406Z"
                writerId: vp5xfr22lyxaal6ovydfvxo5imulaj4t
        m: []
        python_version: 3.12.0
        t:
            "1":
                - 1
            "2":
                - 1
            "3":
                - 13
                - 16
                - 35
            "4": 3.12.0
            "5": 0.21.0
            "12": 0.21.0
            "13": darwin-arm64
batch_size:
    value: 64
buffer_size:
    value: 100000
capture_video:
    value: false
cuda:
    value: true
end_e:
    value: 0
env_id:
    value: ALE/Pong-v5
exp_name:
    value: notebook_run
exploration_fraction:
    value: 0
gamma:
    value: 0.9848904522431526
hf_entity:
    value: ""
learning_rate:
    value: 0.00024159304323406795
learning_starts:
    value: 80000
n_atoms:
    value: 51
n_step:
    value: 3
num_envs:
    value: 1
prioritized_replay_alpha:
    value: 0.5090792103106702
prioritized_replay_beta:
    value: 0.5472741836625601
prioritized_replay_eps:
    value: 1e-06
save_model:
    value: true
seed:
    value: 42
start_e:
    value: 0
target_network_frequency:
    value: 500
tau:
    value: 0.007881662783282053
torch_deterministic:
    value: true
total_timesteps:
    value: 10000000
track:
    value: true
train_frequency:
    value: 4
upload_model:
    value: false
v_max:
    value: 10
v_min:
    value: -10
wandb_entity:
    value: null
wandb_project_name:
    value: cleanRL
