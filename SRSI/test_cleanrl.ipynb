{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c93944ab-b088-47af-9e48-4214db55a49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./venv/lib/python3.12/site-packages (2.2.6)\n",
      "Requirement already satisfied: gymnasium in ./venv/lib/python3.12/site-packages (1.2.0)\n",
      "Requirement already satisfied: torch in ./venv/lib/python3.12/site-packages (2.7.1)\n",
      "Collecting matplotlib\n",
      "  Obtaining dependency information for matplotlib from https://files.pythonhosted.org/packages/0f/70/d61a591958325c357204870b5e7b164f93f2a8cca1dc6ce940f563909a13/matplotlib-3.10.3-cp312-cp312-macosx_11_0_arm64.whl.metadata\n",
      "  Using cached matplotlib-3.10.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: ale-py in ./venv/lib/python3.12/site-packages (0.11.2)\n",
      "Requirement already satisfied: opencv-python in ./venv/lib/python3.12/site-packages (4.12.0.88)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in ./venv/lib/python3.12/site-packages (from gymnasium) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in ./venv/lib/python3.12/site-packages (from gymnasium) (4.14.1)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in ./venv/lib/python3.12/site-packages (from gymnasium) (0.0.4)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.12/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.12/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./venv/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.12/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./venv/lib/python3.12/site-packages (from torch) (2025.7.0)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Obtaining dependency information for contourpy>=1.0.1 from https://files.pythonhosted.org/packages/53/3e/405b59cfa13021a56bba395a6b3aca8cec012b45bf177b0eaf7a202cde2c/contourpy-1.3.3-cp312-cp312-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading contourpy-1.3.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Obtaining dependency information for cycler>=0.10 from https://files.pythonhosted.org/packages/e7/05/c19819d5e3d95294a6f5947fb9b9629efb316b96de511b418c53d245aae6/cycler-0.12.1-py3-none-any.whl.metadata\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Obtaining dependency information for fonttools>=4.22.0 from https://files.pythonhosted.org/packages/e2/77/b1c8af22f4265e951cd2e5535dbef8859efcef4fb8dee742d368c967cddb/fonttools-4.59.0-cp312-cp312-macosx_10_13_universal2.whl.metadata\n",
      "  Downloading fonttools-4.59.0-cp312-cp312-macosx_10_13_universal2.whl.metadata (107 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.9/107.9 kB\u001b[0m \u001b[31m265.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Obtaining dependency information for kiwisolver>=1.3.1 from https://files.pythonhosted.org/packages/60/26/d6a0db6785dd35d3ba5bf2b2df0aedc5af089962c6eb2cbf67a15b81369e/kiwisolver-1.4.8-cp312-cp312-macosx_11_0_arm64.whl.metadata\n",
      "  Using cached kiwisolver-1.4.8-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./venv/lib/python3.12/site-packages (from matplotlib) (11.3.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Obtaining dependency information for pyparsing>=2.3.1 from https://files.pythonhosted.org/packages/05/e7/df2285f3d08fee213f2d041540fa4fc9ca6c2d44cf36d3a035bf2a8d2bcc/pyparsing-3.2.3-py3-none-any.whl.metadata\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./venv/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Using cached matplotlib-3.10.3-cp312-cp312-macosx_11_0_arm64.whl (8.1 MB)\n",
      "Downloading contourpy-1.3.3-cp312-cp312-macosx_11_0_arm64.whl (273 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.0/274.0 kB\u001b[0m \u001b[31m814.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.59.0-cp312-cp312-macosx_10_13_universal2.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached kiwisolver-1.4.8-cp312-cp312-macosx_11_0_arm64.whl (65 kB)\n",
      "Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.59.0 kiwisolver-1.4.8 matplotlib-3.10.3 pyparsing-3.2.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy gymnasium torch matplotlib ale-py opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17078d6e-dfea-4894-af60-8a443079b16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Model loaded from notebook_run123213213.cleanrl_model\n",
      "Starting visualization for 3 episodes...\n",
      "Episode 1 finished with reward: 11.0\n",
      "Episode 2 finished with reward: 4.0\n",
      "Episode 3 finished with reward: 8.0\n"
     ]
    }
   ],
   "source": [
    "# model_visualization.py\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import gymnasium as gym\n",
    "import time\n",
    "import ale_py\n",
    "\n",
    "# Define the same QNetwork architecture used in training\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, env):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(4, 32, 8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3136, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, env.action_space.n),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x / 255.0)\n",
    "\n",
    "# Define environment wrappers\n",
    "class NoopResetEnv(gym.Wrapper):\n",
    "    def __init__(self, env, noop_max=30):\n",
    "        super().__init__(env)\n",
    "        self.noop_max = noop_max\n",
    "        self.override_num_noops = None\n",
    "        self.noop_action = 0\n",
    "        assert env.unwrapped.get_action_meanings()[0] == \"NOOP\"\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        self.env.reset(**kwargs)\n",
    "        if self.override_num_noops is not None:\n",
    "            noops = self.override_num_noops\n",
    "        else:\n",
    "            noops = self.unwrapped.np_random.integers(1, self.noop_max + 1)\n",
    "        assert noops > 0\n",
    "        obs = np.zeros(0)\n",
    "        info = {}\n",
    "        for _ in range(noops):\n",
    "            obs, _, terminated, truncated, info = self.env.step(self.noop_action)\n",
    "            if terminated or truncated:\n",
    "                obs, info = self.env.reset(**kwargs)\n",
    "        return obs, info\n",
    "\n",
    "class MaxAndSkipEnv(gym.Wrapper):\n",
    "    def __init__(self, env, skip=4):\n",
    "        super().__init__(env)\n",
    "        self._obs_buffer = np.zeros((2, *env.observation_space.shape), dtype=env.observation_space.dtype)\n",
    "        self._skip = skip\n",
    "\n",
    "    def step(self, action):\n",
    "        total_reward = 0.0\n",
    "        terminated = truncated = False\n",
    "        for i in range(self._skip):\n",
    "            obs, reward, terminated, truncated, info = self.env.step(action)\n",
    "            done = terminated or truncated\n",
    "            if i == self._skip - 2:\n",
    "                self._obs_buffer[0] = obs\n",
    "            if i == self._skip - 1:\n",
    "                self._obs_buffer[1] = obs\n",
    "            total_reward += float(reward)\n",
    "            if done:\n",
    "                break\n",
    "        max_frame = self._obs_buffer.max(axis=0)\n",
    "        return max_frame, total_reward, terminated, truncated, info\n",
    "\n",
    "class EpisodicLifeEnv(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.lives = 0\n",
    "        self.was_real_done = True\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, terminated, truncated, info = self.env.step(action)\n",
    "        self.was_real_done = terminated or truncated\n",
    "        lives = self.env.unwrapped.ale.lives()\n",
    "        if 0 < lives < self.lives:\n",
    "            terminated = True\n",
    "        self.lives = lives\n",
    "        return obs, reward, terminated, truncated, info\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        if self.was_real_done:\n",
    "            obs, info = self.env.reset(**kwargs)\n",
    "        else:\n",
    "            obs, _, terminated, truncated, info = self.env.step(0)\n",
    "            if terminated or truncated:\n",
    "                obs, info = self.env.reset(**kwargs)\n",
    "        self.lives = self.env.unwrapped.ale.lives()\n",
    "        return obs, info\n",
    "\n",
    "class FireResetEnv(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        assert env.unwrapped.get_action_meanings()[1] == \"FIRE\"\n",
    "        assert len(env.unwrapped.get_action_meanings()) >= 3\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        self.env.reset(**kwargs)\n",
    "        obs, _, terminated, truncated, _ = self.env.step(1)\n",
    "        if terminated or truncated:\n",
    "            self.env.reset(**kwargs)\n",
    "        obs, _, terminated, truncated, _ = self.env.step(2)\n",
    "        if terminated or truncated:\n",
    "            self.env.reset(**kwargs)\n",
    "        return obs, {}\n",
    "\n",
    "class ClipRewardEnv(gym.RewardWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "\n",
    "    def reward(self, reward):\n",
    "        return np.sign(float(reward))\n",
    "\n",
    "# Function to create the environment with the same wrappers as during training\n",
    "def make_atari_env(env_id, render_mode=None):\n",
    "    if render_mode:\n",
    "        env = gym.make(env_id, obs_type=\"grayscale\", render_mode=render_mode)\n",
    "    else:\n",
    "        env = gym.make(env_id, obs_type=\"grayscale\")\n",
    "    \n",
    "    env = gym.wrappers.RecordEpisodeStatistics(env)\n",
    "    env = NoopResetEnv(env, noop_max=30)\n",
    "    env = MaxAndSkipEnv(env, skip=4)\n",
    "    env = EpisodicLifeEnv(env)\n",
    "    if \"FIRE\" in env.unwrapped.get_action_meanings():\n",
    "        env = FireResetEnv(env)\n",
    "    env = ClipRewardEnv(env)\n",
    "    env = gym.wrappers.ResizeObservation(env, (84, 84))\n",
    "    env = gym.wrappers.FrameStackObservation(env, 4)\n",
    "    \n",
    "    return env\n",
    "\n",
    "# Visualization function that uses the environment's native rendering\n",
    "def visualize_agent(env, model, episodes=5, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Visualize the agent's performance using native environment rendering\n",
    "    \"\"\"\n",
    "    for episode in range(episodes):\n",
    "        obs, _ = env.reset()\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "        \n",
    "        while not done:\n",
    "            # Epsilon-greedy action selection\n",
    "            q_values = model(torch.FloatTensor(obs).unsqueeze(0).to(device))\n",
    "            action = torch.argmax(q_values, dim=1).item()\n",
    "            \n",
    "            # Take action - environment will automatically render to window\n",
    "            obs, reward, terminated, truncated, _ = env.step(action)\n",
    "            done = terminated or truncated\n",
    "            total_reward += reward\n",
    "            \n",
    "            # Add a small delay to make visualization easier to follow\n",
    "            time.sleep(0.02)\n",
    "        \n",
    "        print(f\"Episode {episode+1} finished with reward: {total_reward}\")\n",
    "\n",
    "# Main function to load model and visualize agent\n",
    "def main():\n",
    "    # Parameters\n",
    "    env_id = \"ALE/Pong-v5\"  # Change to your environment\n",
    "    model_path = \"notebook_run123213213.cleanrl_model\"  # Update with your model path\n",
    "    epsilon = 0.01  # Exploration rate during visualization\n",
    "    episodes = 3  # Number of episodes to visualize\n",
    "    \n",
    "    # Check if CUDA is available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Create environment with HUMAN rendering\n",
    "    env = make_atari_env(env_id, render_mode=\"human\")\n",
    "    \n",
    "    # Initialize model\n",
    "    q_network = QNetwork(env).to(device)\n",
    "    \n",
    "    # Load trained model weights\n",
    "    q_network.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    q_network.eval()\n",
    "    \n",
    "    print(f\"Model loaded from {model_path}\")\n",
    "    print(f\"Starting visualization for {episodes} episodes...\")\n",
    "    \n",
    "    # Run visualization\n",
    "    visualize_agent(env, q_network, episodes, device)\n",
    "    \n",
    "    env.close()\n",
    "\n",
    "# Run the visualization\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4db918c-b5f1-48b7-b7fd-0419ca4f64b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
